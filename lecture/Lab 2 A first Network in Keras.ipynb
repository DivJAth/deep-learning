{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and training multi-layer artificial neural networks in Keras\n",
    "\n",
    "Fortunately, the past decade has resulted in a large number of tools to efficiently work with very large, so-called deep neural networks. Among the more prominent tools are <a href=\"https://en.wikipedia.org/wiki/Theano_(software)\">theano</a> and <a href=\"https://en.wikipedia.org/wiki/TensorFlow\">Tensorflow</a>, from the University of Montreal and Google Inc., respectively, and the <a href=\"https://en.wikipedia.org/wiki/Keras\">Keras</a> library to conveniently interface with them. We will be using Keras in this class to study the most important deep neural network architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a series of standard models, the simplest being a sequential model that allows the user to stack layers of artifical neurons together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_dim=3,kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example creates a sequential neural network with one \"dense\" layer with 2 artificial neurons, input dimension of 3, and uniformly random initial weights. Keras offers the following options <code>random_uniform</code>, <code>random_normal</code>, and <code>zero</code>, which are self-explanatory. Using a <i>dense</i> layer means that all inputs to a layer are connected to every neuron, and all outputs of a layer connect to all neurons of the next layer. The multi-layer perceptron shown above is a dense network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a first ANN\n",
    "\n",
    "Example from Antonio Gulli, “Deep Learning with Keras.” The MNIST data set is a collection of 70000 hand-written digits from 0 to 9 that are provided in a 28x28 matrix. The MNIST data set is part of the ```keras.datasets``` <a href=\"https://keras.io/datasets/\">library</a>. We will further import a simple ```Sequential``` model, creating a ```Dense``` model with custom ```Activation```, the ```SGD``` optimizer, which will be discussed later, and ```np_utils``` for One-Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 200 # how often the dataset will be presented\n",
    "BATCH_SIZE = 48000 # number of training instances before weights are updated\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # stochastic gradient descent\n",
    "#N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "#\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "#\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the dataset using Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for I in range(4):\n",
    "    for J in range(4):\n",
    "        plt.subplot(4,4,I*4+J+1)\n",
    "        plt.imshow(X_train[I*4+J,:].reshape(28,28))\n",
    "plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "In a first step, we define a neural network with two layers: 10 neurons with 784 inputs and a softmax activation layer. As expected, this network has 7850 parameters, 10 times 784 for the weights and 10 for the bias values.\n",
    "\n",
    "In keras, a neural network model consists both of the architecture as well as a choice of an objective function, an optimizer, and a metrics. Note, that we are using <code>categorical_crossentropy</code>, which is more suited than <code>mean_squared_error</code> when calculating hte error between model prediction and training data. The \"metrics\" parameter is similar to the objective function (\"loss\"), but is used when evaluating the model, not during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 2.3382 - categorical_accuracy: 0.1155 - val_loss: 2.3206 - val_categorical_accuracy: 0.1237\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.3242 - categorical_accuracy: 0.1194 - val_loss: 2.3069 - val_categorical_accuracy: 0.1293\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.3106 - categorical_accuracy: 0.1234 - val_loss: 2.2937 - val_categorical_accuracy: 0.1345\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2975 - categorical_accuracy: 0.1279 - val_loss: 2.2809 - val_categorical_accuracy: 0.1396\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2847 - categorical_accuracy: 0.1328 - val_loss: 2.2684 - val_categorical_accuracy: 0.1444\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 2.2723 - categorical_accuracy: 0.1395 - val_loss: 2.2562 - val_categorical_accuracy: 0.1496\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 2.2602 - categorical_accuracy: 0.1446 - val_loss: 2.2442 - val_categorical_accuracy: 0.1571\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 2.2484 - categorical_accuracy: 0.1511 - val_loss: 2.2326 - val_categorical_accuracy: 0.1647\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2368 - categorical_accuracy: 0.1578 - val_loss: 2.2211 - val_categorical_accuracy: 0.1711\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2255 - categorical_accuracy: 0.1648 - val_loss: 2.2099 - val_categorical_accuracy: 0.1803\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2144 - categorical_accuracy: 0.1729 - val_loss: 2.1989 - val_categorical_accuracy: 0.1889\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.2035 - categorical_accuracy: 0.1807 - val_loss: 2.1881 - val_categorical_accuracy: 0.1968\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1928 - categorical_accuracy: 0.1898 - val_loss: 2.1774 - val_categorical_accuracy: 0.2032\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1823 - categorical_accuracy: 0.1972 - val_loss: 2.1669 - val_categorical_accuracy: 0.2118\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 2.1720 - categorical_accuracy: 0.2051 - val_loss: 2.1566 - val_categorical_accuracy: 0.2198\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1618 - categorical_accuracy: 0.2146 - val_loss: 2.1464 - val_categorical_accuracy: 0.2275\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1517 - categorical_accuracy: 0.2241 - val_loss: 2.1363 - val_categorical_accuracy: 0.2379\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1418 - categorical_accuracy: 0.2329 - val_loss: 2.1264 - val_categorical_accuracy: 0.2469\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1320 - categorical_accuracy: 0.2423 - val_loss: 2.1166 - val_categorical_accuracy: 0.2555\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1224 - categorical_accuracy: 0.2518 - val_loss: 2.1069 - val_categorical_accuracy: 0.2652\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1128 - categorical_accuracy: 0.2610 - val_loss: 2.0973 - val_categorical_accuracy: 0.2751\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.1034 - categorical_accuracy: 0.2712 - val_loss: 2.0879 - val_categorical_accuracy: 0.2839\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0941 - categorical_accuracy: 0.2804 - val_loss: 2.0785 - val_categorical_accuracy: 0.2925\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0849 - categorical_accuracy: 0.2897 - val_loss: 2.0692 - val_categorical_accuracy: 0.3027\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 2.0758 - categorical_accuracy: 0.2992 - val_loss: 2.0601 - val_categorical_accuracy: 0.3112\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0668 - categorical_accuracy: 0.3088 - val_loss: 2.0510 - val_categorical_accuracy: 0.3219\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0579 - categorical_accuracy: 0.3183 - val_loss: 2.0420 - val_categorical_accuracy: 0.3304\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0490 - categorical_accuracy: 0.3277 - val_loss: 2.0331 - val_categorical_accuracy: 0.3404\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0403 - categorical_accuracy: 0.3374 - val_loss: 2.0243 - val_categorical_accuracy: 0.3505\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0317 - categorical_accuracy: 0.3466 - val_loss: 2.0156 - val_categorical_accuracy: 0.3611\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0231 - categorical_accuracy: 0.3553 - val_loss: 2.0070 - val_categorical_accuracy: 0.3717\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0146 - categorical_accuracy: 0.3642 - val_loss: 1.9984 - val_categorical_accuracy: 0.3828\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 2.0062 - categorical_accuracy: 0.3741 - val_loss: 1.9899 - val_categorical_accuracy: 0.3923\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9979 - categorical_accuracy: 0.3833 - val_loss: 1.9815 - val_categorical_accuracy: 0.4018\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9896 - categorical_accuracy: 0.3928 - val_loss: 1.9732 - val_categorical_accuracy: 0.4118\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9814 - categorical_accuracy: 0.4017 - val_loss: 1.9649 - val_categorical_accuracy: 0.4207\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9733 - categorical_accuracy: 0.4104 - val_loss: 1.9567 - val_categorical_accuracy: 0.4299\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9653 - categorical_accuracy: 0.4196 - val_loss: 1.9486 - val_categorical_accuracy: 0.4392\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9573 - categorical_accuracy: 0.4280 - val_loss: 1.9405 - val_categorical_accuracy: 0.4482\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9494 - categorical_accuracy: 0.4377 - val_loss: 1.9325 - val_categorical_accuracy: 0.4568\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9416 - categorical_accuracy: 0.4456 - val_loss: 1.9246 - val_categorical_accuracy: 0.4640\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.9338 - categorical_accuracy: 0.4533 - val_loss: 1.9167 - val_categorical_accuracy: 0.4731\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9261 - categorical_accuracy: 0.4612 - val_loss: 1.9089 - val_categorical_accuracy: 0.4793\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9185 - categorical_accuracy: 0.4684 - val_loss: 1.9012 - val_categorical_accuracy: 0.4868\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9109 - categorical_accuracy: 0.4754 - val_loss: 1.8935 - val_categorical_accuracy: 0.4942\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.9034 - categorical_accuracy: 0.4825 - val_loss: 1.8859 - val_categorical_accuracy: 0.5013\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8959 - categorical_accuracy: 0.4899 - val_loss: 1.8783 - val_categorical_accuracy: 0.5084\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.8885 - categorical_accuracy: 0.4966 - val_loss: 1.8708 - val_categorical_accuracy: 0.5156\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8812 - categorical_accuracy: 0.5033 - val_loss: 1.8634 - val_categorical_accuracy: 0.5220\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8739 - categorical_accuracy: 0.5100 - val_loss: 1.8560 - val_categorical_accuracy: 0.5284\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.8667 - categorical_accuracy: 0.5156 - val_loss: 1.8487 - val_categorical_accuracy: 0.5331\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.8595 - categorical_accuracy: 0.5213 - val_loss: 1.8415 - val_categorical_accuracy: 0.5393\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8524 - categorical_accuracy: 0.5273 - val_loss: 1.8342 - val_categorical_accuracy: 0.5454\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8454 - categorical_accuracy: 0.5325 - val_loss: 1.8271 - val_categorical_accuracy: 0.5502\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8384 - categorical_accuracy: 0.5378 - val_loss: 1.8200 - val_categorical_accuracy: 0.5557\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8315 - categorical_accuracy: 0.5433 - val_loss: 1.8130 - val_categorical_accuracy: 0.5612\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8246 - categorical_accuracy: 0.5485 - val_loss: 1.8060 - val_categorical_accuracy: 0.5663\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8177 - categorical_accuracy: 0.5530 - val_loss: 1.7990 - val_categorical_accuracy: 0.5699\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8110 - categorical_accuracy: 0.5582 - val_loss: 1.7921 - val_categorical_accuracy: 0.5739\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.8042 - categorical_accuracy: 0.5624 - val_loss: 1.7853 - val_categorical_accuracy: 0.5782\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7976 - categorical_accuracy: 0.5671 - val_loss: 1.7785 - val_categorical_accuracy: 0.5828\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7909 - categorical_accuracy: 0.5715 - val_loss: 1.7718 - val_categorical_accuracy: 0.5866\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7844 - categorical_accuracy: 0.5758 - val_loss: 1.7651 - val_categorical_accuracy: 0.5912\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7778 - categorical_accuracy: 0.5797 - val_loss: 1.7585 - val_categorical_accuracy: 0.5949\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7714 - categorical_accuracy: 0.5839 - val_loss: 1.7519 - val_categorical_accuracy: 0.5992\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7649 - categorical_accuracy: 0.5882 - val_loss: 1.7454 - val_categorical_accuracy: 0.6028\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.7586 - categorical_accuracy: 0.5919 - val_loss: 1.7389 - val_categorical_accuracy: 0.6060\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7522 - categorical_accuracy: 0.5955 - val_loss: 1.7325 - val_categorical_accuracy: 0.6099\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7459 - categorical_accuracy: 0.5989 - val_loss: 1.7261 - val_categorical_accuracy: 0.6146\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7397 - categorical_accuracy: 0.6019 - val_loss: 1.7198 - val_categorical_accuracy: 0.6181\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7335 - categorical_accuracy: 0.6050 - val_loss: 1.7135 - val_categorical_accuracy: 0.6227\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7274 - categorical_accuracy: 0.6078 - val_loss: 1.7072 - val_categorical_accuracy: 0.6258\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.7213 - categorical_accuracy: 0.6108 - val_loss: 1.7010 - val_categorical_accuracy: 0.6287\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.7152 - categorical_accuracy: 0.6140 - val_loss: 1.6949 - val_categorical_accuracy: 0.6315\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7092 - categorical_accuracy: 0.6167 - val_loss: 1.6888 - val_categorical_accuracy: 0.6357\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.7033 - categorical_accuracy: 0.6198 - val_loss: 1.6827 - val_categorical_accuracy: 0.6392\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6974 - categorical_accuracy: 0.6230 - val_loss: 1.6767 - val_categorical_accuracy: 0.6413\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6915 - categorical_accuracy: 0.6259 - val_loss: 1.6708 - val_categorical_accuracy: 0.6441\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6857 - categorical_accuracy: 0.6284 - val_loss: 1.6648 - val_categorical_accuracy: 0.6467\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6799 - categorical_accuracy: 0.6312 - val_loss: 1.6589 - val_categorical_accuracy: 0.6498\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6742 - categorical_accuracy: 0.6334 - val_loss: 1.6531 - val_categorical_accuracy: 0.6525\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6685 - categorical_accuracy: 0.6364 - val_loss: 1.6473 - val_categorical_accuracy: 0.6562\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.6628 - categorical_accuracy: 0.6387 - val_loss: 1.6416 - val_categorical_accuracy: 0.6587\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6572 - categorical_accuracy: 0.6407 - val_loss: 1.6359 - val_categorical_accuracy: 0.6603\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6517 - categorical_accuracy: 0.6431 - val_loss: 1.6302 - val_categorical_accuracy: 0.6624\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6461 - categorical_accuracy: 0.6451 - val_loss: 1.6246 - val_categorical_accuracy: 0.6644\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.6406 - categorical_accuracy: 0.6474 - val_loss: 1.6190 - val_categorical_accuracy: 0.6666\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.6352 - categorical_accuracy: 0.6498 - val_loss: 1.6134 - val_categorical_accuracy: 0.6687\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6298 - categorical_accuracy: 0.6518 - val_loss: 1.6079 - val_categorical_accuracy: 0.6706\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6244 - categorical_accuracy: 0.6534 - val_loss: 1.6025 - val_categorical_accuracy: 0.6723\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6191 - categorical_accuracy: 0.6554 - val_loss: 1.5971 - val_categorical_accuracy: 0.6747\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6138 - categorical_accuracy: 0.6574 - val_loss: 1.5917 - val_categorical_accuracy: 0.6763\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6086 - categorical_accuracy: 0.6594 - val_loss: 1.5863 - val_categorical_accuracy: 0.6777\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.6034 - categorical_accuracy: 0.6612 - val_loss: 1.5810 - val_categorical_accuracy: 0.6792\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5982 - categorical_accuracy: 0.6628 - val_loss: 1.5758 - val_categorical_accuracy: 0.6810\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5931 - categorical_accuracy: 0.6647 - val_loss: 1.5705 - val_categorical_accuracy: 0.6830\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.5880 - categorical_accuracy: 0.6664 - val_loss: 1.5653 - val_categorical_accuracy: 0.6843\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5829 - categorical_accuracy: 0.6682 - val_loss: 1.5602 - val_categorical_accuracy: 0.6870\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5779 - categorical_accuracy: 0.6702 - val_loss: 1.5551 - val_categorical_accuracy: 0.6884\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.5729 - categorical_accuracy: 0.6722 - val_loss: 1.5500 - val_categorical_accuracy: 0.6893\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.5680 - categorical_accuracy: 0.6740 - val_loss: 1.5450 - val_categorical_accuracy: 0.6906\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5631 - categorical_accuracy: 0.6757 - val_loss: 1.5400 - val_categorical_accuracy: 0.6922\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5582 - categorical_accuracy: 0.6774 - val_loss: 1.5350 - val_categorical_accuracy: 0.6933\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5534 - categorical_accuracy: 0.6789 - val_loss: 1.5301 - val_categorical_accuracy: 0.6948\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5486 - categorical_accuracy: 0.6804 - val_loss: 1.5252 - val_categorical_accuracy: 0.6957\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5438 - categorical_accuracy: 0.6817 - val_loss: 1.5203 - val_categorical_accuracy: 0.6976\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.5391 - categorical_accuracy: 0.6830 - val_loss: 1.5155 - val_categorical_accuracy: 0.6989\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5344 - categorical_accuracy: 0.6845 - val_loss: 1.5107 - val_categorical_accuracy: 0.7000\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5297 - categorical_accuracy: 0.6857 - val_loss: 1.5059 - val_categorical_accuracy: 0.7017\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5251 - categorical_accuracy: 0.6869 - val_loss: 1.5012 - val_categorical_accuracy: 0.7036\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5205 - categorical_accuracy: 0.6880 - val_loss: 1.4965 - val_categorical_accuracy: 0.7048\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5159 - categorical_accuracy: 0.6893 - val_loss: 1.4919 - val_categorical_accuracy: 0.7063\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5114 - categorical_accuracy: 0.6906 - val_loss: 1.4872 - val_categorical_accuracy: 0.7080\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5069 - categorical_accuracy: 0.6919 - val_loss: 1.4826 - val_categorical_accuracy: 0.7096\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.5024 - categorical_accuracy: 0.6931 - val_loss: 1.4781 - val_categorical_accuracy: 0.7113\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4980 - categorical_accuracy: 0.6944 - val_loss: 1.4736 - val_categorical_accuracy: 0.7128\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4936 - categorical_accuracy: 0.6955 - val_loss: 1.4691 - val_categorical_accuracy: 0.7139\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4892 - categorical_accuracy: 0.6966 - val_loss: 1.4646 - val_categorical_accuracy: 0.7152\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4849 - categorical_accuracy: 0.6978 - val_loss: 1.4602 - val_categorical_accuracy: 0.7166\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4805 - categorical_accuracy: 0.6991 - val_loss: 1.4558 - val_categorical_accuracy: 0.7181\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4763 - categorical_accuracy: 0.7005 - val_loss: 1.4514 - val_categorical_accuracy: 0.7195\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4720 - categorical_accuracy: 0.7014 - val_loss: 1.4471 - val_categorical_accuracy: 0.7208\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4678 - categorical_accuracy: 0.7023 - val_loss: 1.4428 - val_categorical_accuracy: 0.7218\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4636 - categorical_accuracy: 0.7034 - val_loss: 1.4385 - val_categorical_accuracy: 0.7233\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4595 - categorical_accuracy: 0.7045 - val_loss: 1.4342 - val_categorical_accuracy: 0.7243\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4553 - categorical_accuracy: 0.7054 - val_loss: 1.4300 - val_categorical_accuracy: 0.7255\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4512 - categorical_accuracy: 0.7064 - val_loss: 1.4258 - val_categorical_accuracy: 0.7267\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4472 - categorical_accuracy: 0.7075 - val_loss: 1.4217 - val_categorical_accuracy: 0.7278\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4431 - categorical_accuracy: 0.7085 - val_loss: 1.4176 - val_categorical_accuracy: 0.7291\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4391 - categorical_accuracy: 0.7095 - val_loss: 1.4135 - val_categorical_accuracy: 0.7303\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4351 - categorical_accuracy: 0.7105 - val_loss: 1.4094 - val_categorical_accuracy: 0.7312\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4311 - categorical_accuracy: 0.7114 - val_loss: 1.4053 - val_categorical_accuracy: 0.7321\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4272 - categorical_accuracy: 0.7123 - val_loss: 1.4013 - val_categorical_accuracy: 0.7333\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4233 - categorical_accuracy: 0.7129 - val_loss: 1.3973 - val_categorical_accuracy: 0.7346\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.4194 - categorical_accuracy: 0.7138 - val_loss: 1.3934 - val_categorical_accuracy: 0.7359\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.4156 - categorical_accuracy: 0.7147 - val_loss: 1.3895 - val_categorical_accuracy: 0.7368\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4118 - categorical_accuracy: 0.7155 - val_loss: 1.3855 - val_categorical_accuracy: 0.7381\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4080 - categorical_accuracy: 0.7163 - val_loss: 1.3817 - val_categorical_accuracy: 0.7388\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4042 - categorical_accuracy: 0.7171 - val_loss: 1.3778 - val_categorical_accuracy: 0.7391\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.4004 - categorical_accuracy: 0.7178 - val_loss: 1.3740 - val_categorical_accuracy: 0.7395\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3967 - categorical_accuracy: 0.7187 - val_loss: 1.3702 - val_categorical_accuracy: 0.7402\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3930 - categorical_accuracy: 0.7195 - val_loss: 1.3664 - val_categorical_accuracy: 0.7414\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3894 - categorical_accuracy: 0.7204 - val_loss: 1.3627 - val_categorical_accuracy: 0.7427\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3857 - categorical_accuracy: 0.7213 - val_loss: 1.3589 - val_categorical_accuracy: 0.7438\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3821 - categorical_accuracy: 0.7220 - val_loss: 1.3552 - val_categorical_accuracy: 0.7445\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3785 - categorical_accuracy: 0.7225 - val_loss: 1.3516 - val_categorical_accuracy: 0.7456\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3749 - categorical_accuracy: 0.7234 - val_loss: 1.3479 - val_categorical_accuracy: 0.7469\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3714 - categorical_accuracy: 0.7243 - val_loss: 1.3443 - val_categorical_accuracy: 0.7481\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3679 - categorical_accuracy: 0.7249 - val_loss: 1.3407 - val_categorical_accuracy: 0.7488\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3644 - categorical_accuracy: 0.7258 - val_loss: 1.3371 - val_categorical_accuracy: 0.7498\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3609 - categorical_accuracy: 0.7264 - val_loss: 1.3336 - val_categorical_accuracy: 0.7508\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3574 - categorical_accuracy: 0.7273 - val_loss: 1.3300 - val_categorical_accuracy: 0.7511\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3540 - categorical_accuracy: 0.7280 - val_loss: 1.3265 - val_categorical_accuracy: 0.7520\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3506 - categorical_accuracy: 0.7287 - val_loss: 1.3231 - val_categorical_accuracy: 0.7528\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3472 - categorical_accuracy: 0.7294 - val_loss: 1.3196 - val_categorical_accuracy: 0.7532\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3439 - categorical_accuracy: 0.7303 - val_loss: 1.3162 - val_categorical_accuracy: 0.7537\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3405 - categorical_accuracy: 0.7310 - val_loss: 1.3128 - val_categorical_accuracy: 0.7547\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3372 - categorical_accuracy: 0.7317 - val_loss: 1.3094 - val_categorical_accuracy: 0.7555\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3339 - categorical_accuracy: 0.7328 - val_loss: 1.3060 - val_categorical_accuracy: 0.7561\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3307 - categorical_accuracy: 0.7333 - val_loss: 1.3027 - val_categorical_accuracy: 0.7567\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3274 - categorical_accuracy: 0.7342 - val_loss: 1.2993 - val_categorical_accuracy: 0.7576\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3242 - categorical_accuracy: 0.7348 - val_loss: 1.2960 - val_categorical_accuracy: 0.7588\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3210 - categorical_accuracy: 0.7355 - val_loss: 1.2928 - val_categorical_accuracy: 0.7594\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3178 - categorical_accuracy: 0.7360 - val_loss: 1.2895 - val_categorical_accuracy: 0.7602\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3146 - categorical_accuracy: 0.7368 - val_loss: 1.2863 - val_categorical_accuracy: 0.7605\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3115 - categorical_accuracy: 0.7376 - val_loss: 1.2830 - val_categorical_accuracy: 0.7611\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.3083 - categorical_accuracy: 0.7380 - val_loss: 1.2798 - val_categorical_accuracy: 0.7620\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3052 - categorical_accuracy: 0.7386 - val_loss: 1.2767 - val_categorical_accuracy: 0.7627\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.3022 - categorical_accuracy: 0.7394 - val_loss: 1.2735 - val_categorical_accuracy: 0.7632\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2991 - categorical_accuracy: 0.7399 - val_loss: 1.2704 - val_categorical_accuracy: 0.7636\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2960 - categorical_accuracy: 0.7405 - val_loss: 1.2673 - val_categorical_accuracy: 0.7642\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2930 - categorical_accuracy: 0.7410 - val_loss: 1.2642 - val_categorical_accuracy: 0.7655\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2900 - categorical_accuracy: 0.7416 - val_loss: 1.2611 - val_categorical_accuracy: 0.7660\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2870 - categorical_accuracy: 0.7423 - val_loss: 1.2580 - val_categorical_accuracy: 0.7667\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2841 - categorical_accuracy: 0.7427 - val_loss: 1.2550 - val_categorical_accuracy: 0.7670\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2811 - categorical_accuracy: 0.7435 - val_loss: 1.2520 - val_categorical_accuracy: 0.7677\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2782 - categorical_accuracy: 0.7438 - val_loss: 1.2490 - val_categorical_accuracy: 0.7684\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2753 - categorical_accuracy: 0.7443 - val_loss: 1.2460 - val_categorical_accuracy: 0.7690\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2724 - categorical_accuracy: 0.7450 - val_loss: 1.2431 - val_categorical_accuracy: 0.7693\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.2695 - categorical_accuracy: 0.7458 - val_loss: 1.2401 - val_categorical_accuracy: 0.7697\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2666 - categorical_accuracy: 0.7464 - val_loss: 1.2372 - val_categorical_accuracy: 0.7702\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2638 - categorical_accuracy: 0.7470 - val_loss: 1.2343 - val_categorical_accuracy: 0.7710\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2610 - categorical_accuracy: 0.7475 - val_loss: 1.2314 - val_categorical_accuracy: 0.7717\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2582 - categorical_accuracy: 0.7479 - val_loss: 1.2285 - val_categorical_accuracy: 0.7723\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2554 - categorical_accuracy: 0.7484 - val_loss: 1.2257 - val_categorical_accuracy: 0.7728\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2526 - categorical_accuracy: 0.7489 - val_loss: 1.2229 - val_categorical_accuracy: 0.7736\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2499 - categorical_accuracy: 0.7494 - val_loss: 1.2200 - val_categorical_accuracy: 0.7737\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2471 - categorical_accuracy: 0.7498 - val_loss: 1.2172 - val_categorical_accuracy: 0.7746\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2444 - categorical_accuracy: 0.7504 - val_loss: 1.2145 - val_categorical_accuracy: 0.7749\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2417 - categorical_accuracy: 0.7510 - val_loss: 1.2117 - val_categorical_accuracy: 0.7755\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.2390 - categorical_accuracy: 0.7517 - val_loss: 1.2090 - val_categorical_accuracy: 0.7760\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2364 - categorical_accuracy: 0.7522 - val_loss: 1.2062 - val_categorical_accuracy: 0.7764\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2337 - categorical_accuracy: 0.7525 - val_loss: 1.2035 - val_categorical_accuracy: 0.7767\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2311 - categorical_accuracy: 0.7531 - val_loss: 1.2008 - val_categorical_accuracy: 0.7770\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2285 - categorical_accuracy: 0.7536 - val_loss: 1.1981 - val_categorical_accuracy: 0.7774\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2259 - categorical_accuracy: 0.7542 - val_loss: 1.1955 - val_categorical_accuracy: 0.7780\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2233 - categorical_accuracy: 0.7545 - val_loss: 1.1928 - val_categorical_accuracy: 0.7785\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2207 - categorical_accuracy: 0.7553 - val_loss: 1.1902 - val_categorical_accuracy: 0.7791\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 1.2181 - categorical_accuracy: 0.7558 - val_loss: 1.1876 - val_categorical_accuracy: 0.7793\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 1.2156 - categorical_accuracy: 0.7563 - val_loss: 1.1850 - val_categorical_accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/step\n",
      "Test score: 0.2774650658041239\n",
      "Test accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 92.27% on the test set sounds great, and that this can be achieved using only 7850 parameters - which after all encode all the knowledge about the dataset - is impressive. Yet, misclassifying every tenth digit is of little practical relevance. In fact, even 99.9% would mean that one out of a thousand digits is misread. When using such a network to identify the zip code on a letter, every 200th letter, on average, would be subject to a wrong reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing model complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase the complexity of the model by adding hidden layers. For example, adding two hidden layers with 128 neurons each, increases the number of parameters to 118,282. In this case, we can obtain a test accuracy of 97.61%. You can further increase model complexity, for example by employing 1280 hidden nodes, resulting in more than 2.6M parameters. This will allow you to exceed 99% on training accuracy, but not much more than 98% on the test. At some point, you will learn an exact representation of the training data, even 100% accuracy on the training set, but not be able to train a network that is able to truly understand what to look for in your data. This is known as <i>overfitting</i>. As a rule of thumb, a network should always be trained so that the accuracy of training exceeds that of the test set, but not too much further as the reason is likely overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 10)                8010      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,251,450\n",
      "Trainable params: 1,251,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH=200\n",
    "BATCH_SIZE=128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['categorical_accuracy'])\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes='true', to_file='figs/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to render the neural network graphically using Keras' <code>plot_model</code> module (see above)\n",
    "\n",
    "<center>\n",
    "<img src=\"figs/model.png\" width=\"30%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 1.1919 - categorical_accuracy: 0.7516 - val_loss: 0.5764 - val_categorical_accuracy: 0.8762\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 3s 73us/step - loss: 0.4954 - categorical_accuracy: 0.8772 - val_loss: 0.3919 - val_categorical_accuracy: 0.9008\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 4s 74us/step - loss: 0.3864 - categorical_accuracy: 0.8961 - val_loss: 0.3342 - val_categorical_accuracy: 0.9094\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 4s 73us/step - loss: 0.3401 - categorical_accuracy: 0.9064 - val_loss: 0.3042 - val_categorical_accuracy: 0.9156\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 4s 75us/step - loss: 0.3118 - categorical_accuracy: 0.9130 - val_loss: 0.2838 - val_categorical_accuracy: 0.9207\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 4s 74us/step - loss: 0.2909 - categorical_accuracy: 0.9183 - val_loss: 0.2679 - val_categorical_accuracy: 0.9237\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 4s 77us/step - loss: 0.2749 - categorical_accuracy: 0.9230 - val_loss: 0.2545 - val_categorical_accuracy: 0.9275\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.2610 - categorical_accuracy: 0.9269 - val_loss: 0.2443 - val_categorical_accuracy: 0.9308\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2489 - categorical_accuracy: 0.9307 - val_loss: 0.2356 - val_categorical_accuracy: 0.9338\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.2387 - categorical_accuracy: 0.9339 - val_loss: 0.2258 - val_categorical_accuracy: 0.9367\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.2287 - categorical_accuracy: 0.9365 - val_loss: 0.2183 - val_categorical_accuracy: 0.9387\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.2198 - categorical_accuracy: 0.9388 - val_loss: 0.2123 - val_categorical_accuracy: 0.9416\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.2117 - categorical_accuracy: 0.9412 - val_loss: 0.2044 - val_categorical_accuracy: 0.9442\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.2039 - categorical_accuracy: 0.9429 - val_loss: 0.1987 - val_categorical_accuracy: 0.9458\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1969 - categorical_accuracy: 0.9448 - val_loss: 0.1936 - val_categorical_accuracy: 0.9473\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1901 - categorical_accuracy: 0.9469 - val_loss: 0.1880 - val_categorical_accuracy: 0.9486\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1838 - categorical_accuracy: 0.9489 - val_loss: 0.1848 - val_categorical_accuracy: 0.9498\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1776 - categorical_accuracy: 0.9508 - val_loss: 0.1808 - val_categorical_accuracy: 0.9514\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.1724 - categorical_accuracy: 0.9515 - val_loss: 0.1743 - val_categorical_accuracy: 0.9531\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1671 - categorical_accuracy: 0.9533 - val_loss: 0.1720 - val_categorical_accuracy: 0.9535\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1621 - categorical_accuracy: 0.9546 - val_loss: 0.1657 - val_categorical_accuracy: 0.9548\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1573 - categorical_accuracy: 0.9565 - val_loss: 0.1627 - val_categorical_accuracy: 0.9557\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1529 - categorical_accuracy: 0.9572 - val_loss: 0.1593 - val_categorical_accuracy: 0.9564\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1486 - categorical_accuracy: 0.9585 - val_loss: 0.1561 - val_categorical_accuracy: 0.9568\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.1444 - categorical_accuracy: 0.9608 - val_loss: 0.1525 - val_categorical_accuracy: 0.9580\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1405 - categorical_accuracy: 0.9614 - val_loss: 0.1502 - val_categorical_accuracy: 0.9592\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1365 - categorical_accuracy: 0.9624 - val_loss: 0.1487 - val_categorical_accuracy: 0.9592\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1332 - categorical_accuracy: 0.9634 - val_loss: 0.1448 - val_categorical_accuracy: 0.9608\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1298 - categorical_accuracy: 0.9645 - val_loss: 0.1431 - val_categorical_accuracy: 0.9612\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1265 - categorical_accuracy: 0.9657 - val_loss: 0.1399 - val_categorical_accuracy: 0.9622\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1233 - categorical_accuracy: 0.9658 - val_loss: 0.1376 - val_categorical_accuracy: 0.9622\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.1202 - categorical_accuracy: 0.9671 - val_loss: 0.1355 - val_categorical_accuracy: 0.9622\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.1173 - categorical_accuracy: 0.9677 - val_loss: 0.1337 - val_categorical_accuracy: 0.9628\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1143 - categorical_accuracy: 0.9693 - val_loss: 0.1316 - val_categorical_accuracy: 0.9639\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1119 - categorical_accuracy: 0.9697 - val_loss: 0.1297 - val_categorical_accuracy: 0.9640\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1091 - categorical_accuracy: 0.9702 - val_loss: 0.1280 - val_categorical_accuracy: 0.9652\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1065 - categorical_accuracy: 0.9711 - val_loss: 0.1257 - val_categorical_accuracy: 0.9653\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1041 - categorical_accuracy: 0.9716 - val_loss: 0.1243 - val_categorical_accuracy: 0.9648\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.1018 - categorical_accuracy: 0.9726 - val_loss: 0.1235 - val_categorical_accuracy: 0.9657\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0997 - categorical_accuracy: 0.9730 - val_loss: 0.1212 - val_categorical_accuracy: 0.9663\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0973 - categorical_accuracy: 0.9738 - val_loss: 0.1193 - val_categorical_accuracy: 0.9666\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.0953 - categorical_accuracy: 0.9742 - val_loss: 0.1180 - val_categorical_accuracy: 0.9668\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0931 - categorical_accuracy: 0.9746 - val_loss: 0.1168 - val_categorical_accuracy: 0.9675\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0910 - categorical_accuracy: 0.9756 - val_loss: 0.1168 - val_categorical_accuracy: 0.9670\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0891 - categorical_accuracy: 0.9760 - val_loss: 0.1145 - val_categorical_accuracy: 0.9684\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0872 - categorical_accuracy: 0.9767 - val_loss: 0.1134 - val_categorical_accuracy: 0.9683\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0854 - categorical_accuracy: 0.9776 - val_loss: 0.1119 - val_categorical_accuracy: 0.9693\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.0835 - categorical_accuracy: 0.9777 - val_loss: 0.1114 - val_categorical_accuracy: 0.9687\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.0819 - categorical_accuracy: 0.9781 - val_loss: 0.1098 - val_categorical_accuracy: 0.9692\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.0802 - categorical_accuracy: 0.9789 - val_loss: 0.1088 - val_categorical_accuracy: 0.9693\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.0785 - categorical_accuracy: 0.9792 - val_loss: 0.1082 - val_categorical_accuracy: 0.9697\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0770 - categorical_accuracy: 0.9795 - val_loss: 0.1070 - val_categorical_accuracy: 0.9696\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.0755 - categorical_accuracy: 0.9804 - val_loss: 0.1057 - val_categorical_accuracy: 0.9704\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.0739 - categorical_accuracy: 0.9809 - val_loss: 0.1054 - val_categorical_accuracy: 0.9696\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.0724 - categorical_accuracy: 0.9812 - val_loss: 0.1043 - val_categorical_accuracy: 0.9703\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0711 - categorical_accuracy: 0.9817 - val_loss: 0.1032 - val_categorical_accuracy: 0.9710\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.0697 - categorical_accuracy: 0.9824 - val_loss: 0.1020 - val_categorical_accuracy: 0.9711\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.0682 - categorical_accuracy: 0.9827 - val_loss: 0.1021 - val_categorical_accuracy: 0.9718\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.0669 - categorical_accuracy: 0.9830 - val_loss: 0.1012 - val_categorical_accuracy: 0.9712\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 6s 118us/step - loss: 0.0657 - categorical_accuracy: 0.9833 - val_loss: 0.1001 - val_categorical_accuracy: 0.9716\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0645 - categorical_accuracy: 0.9836 - val_loss: 0.0996 - val_categorical_accuracy: 0.9714\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.0632 - categorical_accuracy: 0.9840 - val_loss: 0.0983 - val_categorical_accuracy: 0.9726\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0620 - categorical_accuracy: 0.9841 - val_loss: 0.0984 - val_categorical_accuracy: 0.9722\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 4s 94us/step - loss: 0.0608 - categorical_accuracy: 0.9846 - val_loss: 0.0975 - val_categorical_accuracy: 0.9723\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0596 - categorical_accuracy: 0.9850 - val_loss: 0.0966 - val_categorical_accuracy: 0.9720\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.0586 - categorical_accuracy: 0.9852 - val_loss: 0.0970 - val_categorical_accuracy: 0.9723\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.0575 - categorical_accuracy: 0.9856 - val_loss: 0.0953 - val_categorical_accuracy: 0.9728\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.0564 - categorical_accuracy: 0.9857 - val_loss: 0.0953 - val_categorical_accuracy: 0.9721\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.0554 - categorical_accuracy: 0.9861 - val_loss: 0.0947 - val_categorical_accuracy: 0.9728\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0544 - categorical_accuracy: 0.9863 - val_loss: 0.0934 - val_categorical_accuracy: 0.9732\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.0534 - categorical_accuracy: 0.9867 - val_loss: 0.0928 - val_categorical_accuracy: 0.9732\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.0525 - categorical_accuracy: 0.9870 - val_loss: 0.0921 - val_categorical_accuracy: 0.9737\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.0515 - categorical_accuracy: 0.9871 - val_loss: 0.0917 - val_categorical_accuracy: 0.9743\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.0506 - categorical_accuracy: 0.9876 - val_loss: 0.0920 - val_categorical_accuracy: 0.9742\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 5s 111us/step - loss: 0.0497 - categorical_accuracy: 0.9878 - val_loss: 0.0917 - val_categorical_accuracy: 0.9730\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0488 - categorical_accuracy: 0.9880 - val_loss: 0.0908 - val_categorical_accuracy: 0.9734\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0480 - categorical_accuracy: 0.9883 - val_loss: 0.0906 - val_categorical_accuracy: 0.9737\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.0470 - categorical_accuracy: 0.9884 - val_loss: 0.0904 - val_categorical_accuracy: 0.9731\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.0463 - categorical_accuracy: 0.9886 - val_loss: 0.0892 - val_categorical_accuracy: 0.9736\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.0455 - categorical_accuracy: 0.9891 - val_loss: 0.0888 - val_categorical_accuracy: 0.9748\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0447 - categorical_accuracy: 0.9894 - val_loss: 0.0881 - val_categorical_accuracy: 0.9747\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0439 - categorical_accuracy: 0.9895 - val_loss: 0.0877 - val_categorical_accuracy: 0.9749\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0432 - categorical_accuracy: 0.9897 - val_loss: 0.0880 - val_categorical_accuracy: 0.9750\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0424 - categorical_accuracy: 0.9901 - val_loss: 0.0871 - val_categorical_accuracy: 0.9745\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0417 - categorical_accuracy: 0.9900 - val_loss: 0.0868 - val_categorical_accuracy: 0.9752\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0409 - categorical_accuracy: 0.9903 - val_loss: 0.0867 - val_categorical_accuracy: 0.9750\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0404 - categorical_accuracy: 0.9906 - val_loss: 0.0864 - val_categorical_accuracy: 0.9749\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0396 - categorical_accuracy: 0.9908 - val_loss: 0.0858 - val_categorical_accuracy: 0.9744\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0390 - categorical_accuracy: 0.9909 - val_loss: 0.0856 - val_categorical_accuracy: 0.9754\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0384 - categorical_accuracy: 0.9914 - val_loss: 0.0859 - val_categorical_accuracy: 0.9750\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0377 - categorical_accuracy: 0.9916 - val_loss: 0.0849 - val_categorical_accuracy: 0.9758\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0372 - categorical_accuracy: 0.9918 - val_loss: 0.0849 - val_categorical_accuracy: 0.9755\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0365 - categorical_accuracy: 0.9916 - val_loss: 0.0845 - val_categorical_accuracy: 0.9757\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0358 - categorical_accuracy: 0.9921 - val_loss: 0.0851 - val_categorical_accuracy: 0.9748\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0353 - categorical_accuracy: 0.9921 - val_loss: 0.0838 - val_categorical_accuracy: 0.9757\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0347 - categorical_accuracy: 0.9925 - val_loss: 0.0840 - val_categorical_accuracy: 0.9755\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0341 - categorical_accuracy: 0.9926 - val_loss: 0.0845 - val_categorical_accuracy: 0.9752\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.0336 - categorical_accuracy: 0.9927 - val_loss: 0.0848 - val_categorical_accuracy: 0.9749\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.0330 - categorical_accuracy: 0.9930 - val_loss: 0.0832 - val_categorical_accuracy: 0.9759\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 6s 118us/step - loss: 0.0325 - categorical_accuracy: 0.9932 - val_loss: 0.0832 - val_categorical_accuracy: 0.9762\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.0320 - categorical_accuracy: 0.9932 - val_loss: 0.0826 - val_categorical_accuracy: 0.9754\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.0315 - categorical_accuracy: 0.9934 - val_loss: 0.0824 - val_categorical_accuracy: 0.9761\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0309 - categorical_accuracy: 0.9936 - val_loss: 0.0826 - val_categorical_accuracy: 0.9758\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0305 - categorical_accuracy: 0.9939 - val_loss: 0.0828 - val_categorical_accuracy: 0.9762\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0300 - categorical_accuracy: 0.9936 - val_loss: 0.0820 - val_categorical_accuracy: 0.9756\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0295 - categorical_accuracy: 0.9940 - val_loss: 0.0820 - val_categorical_accuracy: 0.9758\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0291 - categorical_accuracy: 0.9940 - val_loss: 0.0816 - val_categorical_accuracy: 0.9760\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0286 - categorical_accuracy: 0.9943 - val_loss: 0.0817 - val_categorical_accuracy: 0.9761\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.0281 - categorical_accuracy: 0.9945 - val_loss: 0.0817 - val_categorical_accuracy: 0.9758\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0277 - categorical_accuracy: 0.9946 - val_loss: 0.0813 - val_categorical_accuracy: 0.9759\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0273 - categorical_accuracy: 0.9946 - val_loss: 0.0810 - val_categorical_accuracy: 0.9766\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.0269 - categorical_accuracy: 0.9950 - val_loss: 0.0810 - val_categorical_accuracy: 0.9767\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.0264 - categorical_accuracy: 0.9951 - val_loss: 0.0811 - val_categorical_accuracy: 0.9758\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0260 - categorical_accuracy: 0.9950 - val_loss: 0.0810 - val_categorical_accuracy: 0.9764\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.0256 - categorical_accuracy: 0.9953 - val_loss: 0.0812 - val_categorical_accuracy: 0.9768\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.0252 - categorical_accuracy: 0.9954 - val_loss: 0.0813 - val_categorical_accuracy: 0.9763\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0249 - categorical_accuracy: 0.9956 - val_loss: 0.0814 - val_categorical_accuracy: 0.9758\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0245 - categorical_accuracy: 0.9956 - val_loss: 0.0802 - val_categorical_accuracy: 0.9764\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0241 - categorical_accuracy: 0.9957 - val_loss: 0.0804 - val_categorical_accuracy: 0.9767\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0237 - categorical_accuracy: 0.9959 - val_loss: 0.0803 - val_categorical_accuracy: 0.9765\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0233 - categorical_accuracy: 0.9958 - val_loss: 0.0812 - val_categorical_accuracy: 0.9767\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0230 - categorical_accuracy: 0.9961 - val_loss: 0.0804 - val_categorical_accuracy: 0.9761\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0227 - categorical_accuracy: 0.9961 - val_loss: 0.0796 - val_categorical_accuracy: 0.9766\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.0223 - categorical_accuracy: 0.9964 - val_loss: 0.0800 - val_categorical_accuracy: 0.9767\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0220 - categorical_accuracy: 0.9963 - val_loss: 0.0796 - val_categorical_accuracy: 0.9768\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0216 - categorical_accuracy: 0.9965 - val_loss: 0.0800 - val_categorical_accuracy: 0.9766\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0214 - categorical_accuracy: 0.9965 - val_loss: 0.0803 - val_categorical_accuracy: 0.9762\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0211 - categorical_accuracy: 0.9965 - val_loss: 0.0798 - val_categorical_accuracy: 0.9774\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0207 - categorical_accuracy: 0.9967 - val_loss: 0.0798 - val_categorical_accuracy: 0.9763\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0205 - categorical_accuracy: 0.9965 - val_loss: 0.0795 - val_categorical_accuracy: 0.9766\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0201 - categorical_accuracy: 0.9970 - val_loss: 0.0800 - val_categorical_accuracy: 0.9762\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0199 - categorical_accuracy: 0.9969 - val_loss: 0.0792 - val_categorical_accuracy: 0.9764\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0196 - categorical_accuracy: 0.9970 - val_loss: 0.0801 - val_categorical_accuracy: 0.9766\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0193 - categorical_accuracy: 0.9971 - val_loss: 0.0792 - val_categorical_accuracy: 0.9768\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0190 - categorical_accuracy: 0.9972 - val_loss: 0.0794 - val_categorical_accuracy: 0.9768\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0187 - categorical_accuracy: 0.9973 - val_loss: 0.0797 - val_categorical_accuracy: 0.9766\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0185 - categorical_accuracy: 0.9974 - val_loss: 0.0794 - val_categorical_accuracy: 0.9764\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0183 - categorical_accuracy: 0.9974 - val_loss: 0.0786 - val_categorical_accuracy: 0.9767\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0180 - categorical_accuracy: 0.9975 - val_loss: 0.0786 - val_categorical_accuracy: 0.9770\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0177 - categorical_accuracy: 0.9974 - val_loss: 0.0785 - val_categorical_accuracy: 0.9771\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.0175 - categorical_accuracy: 0.9976 - val_loss: 0.0783 - val_categorical_accuracy: 0.9770\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.0172 - categorical_accuracy: 0.9977 - val_loss: 0.0786 - val_categorical_accuracy: 0.9767\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0170 - categorical_accuracy: 0.9978 - val_loss: 0.0790 - val_categorical_accuracy: 0.9773\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.0168 - categorical_accuracy: 0.9977 - val_loss: 0.0789 - val_categorical_accuracy: 0.9769\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.0165 - categorical_accuracy: 0.9978 - val_loss: 0.0780 - val_categorical_accuracy: 0.9773\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.0163 - categorical_accuracy: 0.9978 - val_loss: 0.0784 - val_categorical_accuracy: 0.9774\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0161 - categorical_accuracy: 0.9979 - val_loss: 0.0787 - val_categorical_accuracy: 0.9768\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0159 - categorical_accuracy: 0.9979 - val_loss: 0.0786 - val_categorical_accuracy: 0.9773\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0156 - categorical_accuracy: 0.9981 - val_loss: 0.0785 - val_categorical_accuracy: 0.9772\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0154 - categorical_accuracy: 0.9982 - val_loss: 0.0789 - val_categorical_accuracy: 0.9777\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0152 - categorical_accuracy: 0.9981 - val_loss: 0.0787 - val_categorical_accuracy: 0.9771\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0150 - categorical_accuracy: 0.9982 - val_loss: 0.0788 - val_categorical_accuracy: 0.9769\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0149 - categorical_accuracy: 0.9982 - val_loss: 0.0781 - val_categorical_accuracy: 0.9773\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0146 - categorical_accuracy: 0.9983 - val_loss: 0.0787 - val_categorical_accuracy: 0.9773\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0144 - categorical_accuracy: 0.9984 - val_loss: 0.0781 - val_categorical_accuracy: 0.9773\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0142 - categorical_accuracy: 0.9984 - val_loss: 0.0784 - val_categorical_accuracy: 0.9772\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0141 - categorical_accuracy: 0.9985 - val_loss: 0.0786 - val_categorical_accuracy: 0.9772\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0139 - categorical_accuracy: 0.9985 - val_loss: 0.0787 - val_categorical_accuracy: 0.9780\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0137 - categorical_accuracy: 0.9984 - val_loss: 0.0783 - val_categorical_accuracy: 0.9774\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0135 - categorical_accuracy: 0.9986 - val_loss: 0.0785 - val_categorical_accuracy: 0.9772\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0133 - categorical_accuracy: 0.9985 - val_loss: 0.0784 - val_categorical_accuracy: 0.9776\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0132 - categorical_accuracy: 0.9986 - val_loss: 0.0787 - val_categorical_accuracy: 0.9774\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0130 - categorical_accuracy: 0.9986 - val_loss: 0.0784 - val_categorical_accuracy: 0.9775\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0128 - categorical_accuracy: 0.9987 - val_loss: 0.0781 - val_categorical_accuracy: 0.9774\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0127 - categorical_accuracy: 0.9987 - val_loss: 0.0786 - val_categorical_accuracy: 0.9776\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0125 - categorical_accuracy: 0.9987 - val_loss: 0.0782 - val_categorical_accuracy: 0.9774\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0124 - categorical_accuracy: 0.9987 - val_loss: 0.0783 - val_categorical_accuracy: 0.9778\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0122 - categorical_accuracy: 0.9989 - val_loss: 0.0785 - val_categorical_accuracy: 0.9785\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0120 - categorical_accuracy: 0.9988 - val_loss: 0.0780 - val_categorical_accuracy: 0.9770\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0119 - categorical_accuracy: 0.9989 - val_loss: 0.0782 - val_categorical_accuracy: 0.9782\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0117 - categorical_accuracy: 0.9989 - val_loss: 0.0788 - val_categorical_accuracy: 0.9780\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0116 - categorical_accuracy: 0.9989 - val_loss: 0.0784 - val_categorical_accuracy: 0.9784\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0114 - categorical_accuracy: 0.9990 - val_loss: 0.0784 - val_categorical_accuracy: 0.9775\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0113 - categorical_accuracy: 0.9991 - val_loss: 0.0789 - val_categorical_accuracy: 0.9777\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0112 - categorical_accuracy: 0.9990 - val_loss: 0.0785 - val_categorical_accuracy: 0.9779\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0111 - categorical_accuracy: 0.9990 - val_loss: 0.0785 - val_categorical_accuracy: 0.9774\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0109 - categorical_accuracy: 0.9991 - val_loss: 0.0789 - val_categorical_accuracy: 0.9775\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0108 - categorical_accuracy: 0.9990 - val_loss: 0.0788 - val_categorical_accuracy: 0.9771\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0106 - categorical_accuracy: 0.9991 - val_loss: 0.0792 - val_categorical_accuracy: 0.9774\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0105 - categorical_accuracy: 0.9990 - val_loss: 0.0787 - val_categorical_accuracy: 0.9778\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0104 - categorical_accuracy: 0.9991 - val_loss: 0.0786 - val_categorical_accuracy: 0.9777\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0103 - categorical_accuracy: 0.9992 - val_loss: 0.0788 - val_categorical_accuracy: 0.9777\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0102 - categorical_accuracy: 0.9991 - val_loss: 0.0791 - val_categorical_accuracy: 0.9771\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0100 - categorical_accuracy: 0.9992 - val_loss: 0.0790 - val_categorical_accuracy: 0.9775\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.0099 - categorical_accuracy: 0.9993 - val_loss: 0.0786 - val_categorical_accuracy: 0.9774\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0098 - categorical_accuracy: 0.9992 - val_loss: 0.0785 - val_categorical_accuracy: 0.9776\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0097 - categorical_accuracy: 0.9992 - val_loss: 0.0786 - val_categorical_accuracy: 0.9773\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0096 - categorical_accuracy: 0.9992 - val_loss: 0.0789 - val_categorical_accuracy: 0.9783\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0095 - categorical_accuracy: 0.9992 - val_loss: 0.0791 - val_categorical_accuracy: 0.9781\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0093 - categorical_accuracy: 0.9993 - val_loss: 0.0793 - val_categorical_accuracy: 0.9773\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.0092 - categorical_accuracy: 0.9993 - val_loss: 0.0791 - val_categorical_accuracy: 0.9786\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0092 - categorical_accuracy: 0.9993 - val_loss: 0.0788 - val_categorical_accuracy: 0.9780\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0090 - categorical_accuracy: 0.9994 - val_loss: 0.0786 - val_categorical_accuracy: 0.9776\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 4s 94us/step - loss: 0.0089 - categorical_accuracy: 0.9992 - val_loss: 0.0791 - val_categorical_accuracy: 0.9782\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.0088 - categorical_accuracy: 0.9993 - val_loss: 0.0791 - val_categorical_accuracy: 0.9785\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0087 - categorical_accuracy: 0.9994 - val_loss: 0.0790 - val_categorical_accuracy: 0.9783\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0086 - categorical_accuracy: 0.9994 - val_loss: 0.0789 - val_categorical_accuracy: 0.9783\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0086 - categorical_accuracy: 0.9993 - val_loss: 0.0792 - val_categorical_accuracy: 0.9779\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0085 - categorical_accuracy: 0.9994 - val_loss: 0.0791 - val_categorical_accuracy: 0.9781\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0083 - categorical_accuracy: 0.9995 - val_loss: 0.0793 - val_categorical_accuracy: 0.9781\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Test score: 0.06835808327557752\n",
      "Test accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training history is available via Keras' <code>history</code> object. Its a dictionary with the following keys (this depends on how the model was compiled). It is particularly helpful to observe where training and test accuracy start to diverge, which is the point at which further training does not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x126436400>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'][:50])\n",
    "plt.plot(history.history['val_categorical_accuracy'][:50])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Categorical accuracy')\n",
    "plt.legend(['Training','Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving network performance (the old way)\n",
    "\n",
    "We note that all training so far has been done on the raw 28x28 bytes data. Furthermore, the 2D input data has been turned into a column vector leaving it up to the network to cherry-pick the salient information. In classic machine learning this has never been done. Instead, the trick has always been to carefully engineer features that both reduce the amount of data the network has to deal with and integrate human expert knowledge as best as possible.\n",
    "\n",
    "Looking at the MNIST data, there are many ideas that come to mind. For example, we might use basic image statistics to generate a first set of features. These could be the percentage of the matrix actually covered by pixels (with the numbers 8 and 9 using more pixels than the number 1, e.g.), the \"center of mass\" of the images with some numbers like 1 and 8 having a center of mass closer to the center and so on. A different approach could be to downsample the image by grouping pixels into groups of 4x4 or even 7x7, and thresholding them. Here, the idea would be that presence of data in the new 16 or 49 \"super-pixels\" would actually suffice to classify the digits. \n",
    "\n",
    "Lets try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import downscale_local_mean # scikit-image\n",
    "\n",
    "(X_train_orig, y_train), (X_test_orig, y_test) = mnist.load_data()\n",
    "\n",
    "X_train=np.zeros((60000,7,7))\n",
    "X_test=np.zeros((10000,7,7))\n",
    "\n",
    "for I in range(X_train.shape[0]):\n",
    "        X_train[I,:,:] = downscale_local_mean(X_train_orig[I,:,:], (4, 4))\n",
    "        X_train[I,:,:] = X_train[I,:,:]/255\n",
    "\n",
    "\n",
    "for I in range(X_test.shape[0]):\n",
    "        X_test[I,:,:] = downscale_local_mean(X_test_orig[I,:,:], (4, 4))\n",
    "        X_test[I,:,:] = X_test[I,:,:]/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for I in range(4):\n",
    "    for J in range(4):\n",
    "        plt.subplot(4,4,I*4+J+1)\n",
    "        plt.imshow(X_train[I*4+J,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 128)               6400      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 24,202\n",
      "Trainable params: 24,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 2.1765 - categorical_accuracy: 0.3643 - val_loss: 2.0326 - val_categorical_accuracy: 0.5904\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 1.8421 - categorical_accuracy: 0.6461 - val_loss: 1.6070 - val_categorical_accuracy: 0.6900\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 1.3875 - categorical_accuracy: 0.7090 - val_loss: 1.1586 - val_categorical_accuracy: 0.7475\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 1.0337 - categorical_accuracy: 0.7576 - val_loss: 0.8869 - val_categorical_accuracy: 0.7910\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.8343 - categorical_accuracy: 0.7900 - val_loss: 0.7373 - val_categorical_accuracy: 0.8187\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.7192 - categorical_accuracy: 0.8118 - val_loss: 0.6467 - val_categorical_accuracy: 0.8355\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.6465 - categorical_accuracy: 0.8260 - val_loss: 0.5877 - val_categorical_accuracy: 0.8441\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.5974 - categorical_accuracy: 0.8370 - val_loss: 0.5476 - val_categorical_accuracy: 0.8513\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5626 - categorical_accuracy: 0.8441 - val_loss: 0.5184 - val_categorical_accuracy: 0.8562\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5368 - categorical_accuracy: 0.8492 - val_loss: 0.4961 - val_categorical_accuracy: 0.8627\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5167 - categorical_accuracy: 0.8530 - val_loss: 0.4795 - val_categorical_accuracy: 0.8633\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5009 - categorical_accuracy: 0.8568 - val_loss: 0.4658 - val_categorical_accuracy: 0.8675\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4880 - categorical_accuracy: 0.8588 - val_loss: 0.4540 - val_categorical_accuracy: 0.8712\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4770 - categorical_accuracy: 0.8614 - val_loss: 0.4443 - val_categorical_accuracy: 0.8721\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4677 - categorical_accuracy: 0.8641 - val_loss: 0.4360 - val_categorical_accuracy: 0.8736\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4594 - categorical_accuracy: 0.8666 - val_loss: 0.4281 - val_categorical_accuracy: 0.8754\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4517 - categorical_accuracy: 0.8687 - val_loss: 0.4218 - val_categorical_accuracy: 0.8768\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4451 - categorical_accuracy: 0.8699 - val_loss: 0.4148 - val_categorical_accuracy: 0.8781\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.4387 - categorical_accuracy: 0.8721 - val_loss: 0.4095 - val_categorical_accuracy: 0.8793\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4326 - categorical_accuracy: 0.8734 - val_loss: 0.4038 - val_categorical_accuracy: 0.8811\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4273 - categorical_accuracy: 0.8744 - val_loss: 0.3988 - val_categorical_accuracy: 0.8816\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.4221 - categorical_accuracy: 0.8757 - val_loss: 0.3936 - val_categorical_accuracy: 0.8837\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.4168 - categorical_accuracy: 0.8776 - val_loss: 0.3895 - val_categorical_accuracy: 0.8845\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4121 - categorical_accuracy: 0.8784 - val_loss: 0.3852 - val_categorical_accuracy: 0.8863\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4076 - categorical_accuracy: 0.8798 - val_loss: 0.3801 - val_categorical_accuracy: 0.8849\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4032 - categorical_accuracy: 0.8809 - val_loss: 0.3771 - val_categorical_accuracy: 0.8877\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3990 - categorical_accuracy: 0.8816 - val_loss: 0.3721 - val_categorical_accuracy: 0.8884\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3946 - categorical_accuracy: 0.8835 - val_loss: 0.3687 - val_categorical_accuracy: 0.8895\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3907 - categorical_accuracy: 0.8840 - val_loss: 0.3643 - val_categorical_accuracy: 0.8912\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3867 - categorical_accuracy: 0.8853 - val_loss: 0.3612 - val_categorical_accuracy: 0.8933\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3827 - categorical_accuracy: 0.8864 - val_loss: 0.3569 - val_categorical_accuracy: 0.8933\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3789 - categorical_accuracy: 0.8873 - val_loss: 0.3557 - val_categorical_accuracy: 0.8927\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3751 - categorical_accuracy: 0.8880 - val_loss: 0.3510 - val_categorical_accuracy: 0.8949\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3714 - categorical_accuracy: 0.8891 - val_loss: 0.3468 - val_categorical_accuracy: 0.8953\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3677 - categorical_accuracy: 0.8897 - val_loss: 0.3437 - val_categorical_accuracy: 0.8972\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3641 - categorical_accuracy: 0.8912 - val_loss: 0.3403 - val_categorical_accuracy: 0.8975\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3607 - categorical_accuracy: 0.8922 - val_loss: 0.3366 - val_categorical_accuracy: 0.8983\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3570 - categorical_accuracy: 0.8929 - val_loss: 0.3332 - val_categorical_accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3535 - categorical_accuracy: 0.8941 - val_loss: 0.3307 - val_categorical_accuracy: 0.9018\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3501 - categorical_accuracy: 0.8950 - val_loss: 0.3272 - val_categorical_accuracy: 0.9020\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3467 - categorical_accuracy: 0.8966 - val_loss: 0.3243 - val_categorical_accuracy: 0.9028\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3433 - categorical_accuracy: 0.8971 - val_loss: 0.3216 - val_categorical_accuracy: 0.9031\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3398 - categorical_accuracy: 0.8979 - val_loss: 0.3181 - val_categorical_accuracy: 0.9047\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3368 - categorical_accuracy: 0.8995 - val_loss: 0.3150 - val_categorical_accuracy: 0.9042\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3334 - categorical_accuracy: 0.9002 - val_loss: 0.3129 - val_categorical_accuracy: 0.9056\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3304 - categorical_accuracy: 0.9007 - val_loss: 0.3093 - val_categorical_accuracy: 0.9072\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3274 - categorical_accuracy: 0.9021 - val_loss: 0.3069 - val_categorical_accuracy: 0.9084\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3244 - categorical_accuracy: 0.9028 - val_loss: 0.3043 - val_categorical_accuracy: 0.9081\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3215 - categorical_accuracy: 0.9037 - val_loss: 0.3023 - val_categorical_accuracy: 0.9083\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3186 - categorical_accuracy: 0.9046 - val_loss: 0.2989 - val_categorical_accuracy: 0.9098\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3156 - categorical_accuracy: 0.9056 - val_loss: 0.2963 - val_categorical_accuracy: 0.9101\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3127 - categorical_accuracy: 0.9064 - val_loss: 0.2940 - val_categorical_accuracy: 0.9118\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3100 - categorical_accuracy: 0.9067 - val_loss: 0.2913 - val_categorical_accuracy: 0.9118\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3072 - categorical_accuracy: 0.9080 - val_loss: 0.2883 - val_categorical_accuracy: 0.9133\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3046 - categorical_accuracy: 0.9090 - val_loss: 0.2866 - val_categorical_accuracy: 0.9136\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3019 - categorical_accuracy: 0.9094 - val_loss: 0.2840 - val_categorical_accuracy: 0.9140\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2993 - categorical_accuracy: 0.9104 - val_loss: 0.2825 - val_categorical_accuracy: 0.9149\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2966 - categorical_accuracy: 0.9111 - val_loss: 0.2796 - val_categorical_accuracy: 0.9167\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2943 - categorical_accuracy: 0.9118 - val_loss: 0.2772 - val_categorical_accuracy: 0.9172\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2917 - categorical_accuracy: 0.9123 - val_loss: 0.2752 - val_categorical_accuracy: 0.9187\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2894 - categorical_accuracy: 0.9135 - val_loss: 0.2724 - val_categorical_accuracy: 0.9187\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2868 - categorical_accuracy: 0.9138 - val_loss: 0.2718 - val_categorical_accuracy: 0.9175\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2847 - categorical_accuracy: 0.9149 - val_loss: 0.2686 - val_categorical_accuracy: 0.9201\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2824 - categorical_accuracy: 0.9151 - val_loss: 0.2671 - val_categorical_accuracy: 0.9203\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2802 - categorical_accuracy: 0.9156 - val_loss: 0.2654 - val_categorical_accuracy: 0.9192\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2780 - categorical_accuracy: 0.9166 - val_loss: 0.2634 - val_categorical_accuracy: 0.9208\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2759 - categorical_accuracy: 0.9175 - val_loss: 0.2611 - val_categorical_accuracy: 0.9227\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2738 - categorical_accuracy: 0.9177 - val_loss: 0.2604 - val_categorical_accuracy: 0.9227\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2719 - categorical_accuracy: 0.9187 - val_loss: 0.2573 - val_categorical_accuracy: 0.9228\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2696 - categorical_accuracy: 0.9195 - val_loss: 0.2564 - val_categorical_accuracy: 0.9237\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2676 - categorical_accuracy: 0.9203 - val_loss: 0.2550 - val_categorical_accuracy: 0.9245\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2656 - categorical_accuracy: 0.9211 - val_loss: 0.2528 - val_categorical_accuracy: 0.9247\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2637 - categorical_accuracy: 0.9212 - val_loss: 0.2510 - val_categorical_accuracy: 0.9256\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2619 - categorical_accuracy: 0.9216 - val_loss: 0.2499 - val_categorical_accuracy: 0.9256\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2600 - categorical_accuracy: 0.9221 - val_loss: 0.2475 - val_categorical_accuracy: 0.9270\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2583 - categorical_accuracy: 0.9229 - val_loss: 0.2466 - val_categorical_accuracy: 0.9262\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2564 - categorical_accuracy: 0.9236 - val_loss: 0.2448 - val_categorical_accuracy: 0.9269\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2546 - categorical_accuracy: 0.9240 - val_loss: 0.2445 - val_categorical_accuracy: 0.9257\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2530 - categorical_accuracy: 0.9238 - val_loss: 0.2421 - val_categorical_accuracy: 0.9277\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2513 - categorical_accuracy: 0.9252 - val_loss: 0.2409 - val_categorical_accuracy: 0.9274\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2496 - categorical_accuracy: 0.9252 - val_loss: 0.2387 - val_categorical_accuracy: 0.9279\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2480 - categorical_accuracy: 0.9255 - val_loss: 0.2376 - val_categorical_accuracy: 0.9287\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2465 - categorical_accuracy: 0.9262 - val_loss: 0.2363 - val_categorical_accuracy: 0.9291\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2447 - categorical_accuracy: 0.9268 - val_loss: 0.2355 - val_categorical_accuracy: 0.9296\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2432 - categorical_accuracy: 0.9268 - val_loss: 0.2346 - val_categorical_accuracy: 0.9290\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2417 - categorical_accuracy: 0.9276 - val_loss: 0.2326 - val_categorical_accuracy: 0.9312\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2403 - categorical_accuracy: 0.9275 - val_loss: 0.2337 - val_categorical_accuracy: 0.9303\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2387 - categorical_accuracy: 0.9286 - val_loss: 0.2309 - val_categorical_accuracy: 0.9307\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2373 - categorical_accuracy: 0.9287 - val_loss: 0.2293 - val_categorical_accuracy: 0.9319\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2359 - categorical_accuracy: 0.9289 - val_loss: 0.2286 - val_categorical_accuracy: 0.9315\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2345 - categorical_accuracy: 0.9293 - val_loss: 0.2275 - val_categorical_accuracy: 0.9327\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2331 - categorical_accuracy: 0.9299 - val_loss: 0.2253 - val_categorical_accuracy: 0.9334\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2316 - categorical_accuracy: 0.9298 - val_loss: 0.2248 - val_categorical_accuracy: 0.9332\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2304 - categorical_accuracy: 0.9302 - val_loss: 0.2243 - val_categorical_accuracy: 0.9328\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2292 - categorical_accuracy: 0.9311 - val_loss: 0.2227 - val_categorical_accuracy: 0.9331\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2278 - categorical_accuracy: 0.9310 - val_loss: 0.2221 - val_categorical_accuracy: 0.9341\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2265 - categorical_accuracy: 0.9315 - val_loss: 0.2208 - val_categorical_accuracy: 0.9343\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2252 - categorical_accuracy: 0.9323 - val_loss: 0.2197 - val_categorical_accuracy: 0.9348\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2240 - categorical_accuracy: 0.9327 - val_loss: 0.2183 - val_categorical_accuracy: 0.9347\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2227 - categorical_accuracy: 0.9327 - val_loss: 0.2173 - val_categorical_accuracy: 0.9347\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2216 - categorical_accuracy: 0.9331 - val_loss: 0.2170 - val_categorical_accuracy: 0.9358\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2203 - categorical_accuracy: 0.9336 - val_loss: 0.2153 - val_categorical_accuracy: 0.9363\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2191 - categorical_accuracy: 0.9341 - val_loss: 0.2143 - val_categorical_accuracy: 0.9361\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2178 - categorical_accuracy: 0.9340 - val_loss: 0.2144 - val_categorical_accuracy: 0.9362\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.2168 - categorical_accuracy: 0.9346 - val_loss: 0.2137 - val_categorical_accuracy: 0.9368\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2157 - categorical_accuracy: 0.9345 - val_loss: 0.2122 - val_categorical_accuracy: 0.9370\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2146 - categorical_accuracy: 0.9347 - val_loss: 0.2114 - val_categorical_accuracy: 0.9377\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2133 - categorical_accuracy: 0.9354 - val_loss: 0.2109 - val_categorical_accuracy: 0.9375\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2123 - categorical_accuracy: 0.9362 - val_loss: 0.2095 - val_categorical_accuracy: 0.9376\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2113 - categorical_accuracy: 0.9361 - val_loss: 0.2082 - val_categorical_accuracy: 0.9383\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2101 - categorical_accuracy: 0.9365 - val_loss: 0.2082 - val_categorical_accuracy: 0.9375\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2091 - categorical_accuracy: 0.9370 - val_loss: 0.2066 - val_categorical_accuracy: 0.9386\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2080 - categorical_accuracy: 0.9372 - val_loss: 0.2057 - val_categorical_accuracy: 0.9389\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2069 - categorical_accuracy: 0.9371 - val_loss: 0.2053 - val_categorical_accuracy: 0.9389\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2060 - categorical_accuracy: 0.9381 - val_loss: 0.2052 - val_categorical_accuracy: 0.9381\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2050 - categorical_accuracy: 0.9380 - val_loss: 0.2039 - val_categorical_accuracy: 0.9397\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2040 - categorical_accuracy: 0.9381 - val_loss: 0.2027 - val_categorical_accuracy: 0.9394\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2030 - categorical_accuracy: 0.9393 - val_loss: 0.2023 - val_categorical_accuracy: 0.9403\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2018 - categorical_accuracy: 0.9389 - val_loss: 0.2019 - val_categorical_accuracy: 0.9404\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2011 - categorical_accuracy: 0.9393 - val_loss: 0.2005 - val_categorical_accuracy: 0.9398\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2001 - categorical_accuracy: 0.9394 - val_loss: 0.1993 - val_categorical_accuracy: 0.9403\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1992 - categorical_accuracy: 0.9401 - val_loss: 0.1987 - val_categorical_accuracy: 0.9410\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1983 - categorical_accuracy: 0.9396 - val_loss: 0.1978 - val_categorical_accuracy: 0.9415\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1973 - categorical_accuracy: 0.9405 - val_loss: 0.1979 - val_categorical_accuracy: 0.9398\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1964 - categorical_accuracy: 0.9403 - val_loss: 0.1967 - val_categorical_accuracy: 0.9419\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1953 - categorical_accuracy: 0.9407 - val_loss: 0.1967 - val_categorical_accuracy: 0.9413\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1946 - categorical_accuracy: 0.9409 - val_loss: 0.1958 - val_categorical_accuracy: 0.9413\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1937 - categorical_accuracy: 0.9416 - val_loss: 0.1945 - val_categorical_accuracy: 0.9418\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1927 - categorical_accuracy: 0.9417 - val_loss: 0.1946 - val_categorical_accuracy: 0.9420\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1919 - categorical_accuracy: 0.9417 - val_loss: 0.1941 - val_categorical_accuracy: 0.9417\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1910 - categorical_accuracy: 0.9420 - val_loss: 0.1927 - val_categorical_accuracy: 0.9421\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1902 - categorical_accuracy: 0.9421 - val_loss: 0.1922 - val_categorical_accuracy: 0.9427\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1894 - categorical_accuracy: 0.9425 - val_loss: 0.1922 - val_categorical_accuracy: 0.9419\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1887 - categorical_accuracy: 0.9426 - val_loss: 0.1904 - val_categorical_accuracy: 0.9438\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1877 - categorical_accuracy: 0.9431 - val_loss: 0.1902 - val_categorical_accuracy: 0.9430\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1870 - categorical_accuracy: 0.9430 - val_loss: 0.1894 - val_categorical_accuracy: 0.9428\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1862 - categorical_accuracy: 0.9434 - val_loss: 0.1893 - val_categorical_accuracy: 0.9437\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1854 - categorical_accuracy: 0.9439 - val_loss: 0.1886 - val_categorical_accuracy: 0.9435\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1846 - categorical_accuracy: 0.9445 - val_loss: 0.1878 - val_categorical_accuracy: 0.9435\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1839 - categorical_accuracy: 0.9441 - val_loss: 0.1871 - val_categorical_accuracy: 0.9443\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1831 - categorical_accuracy: 0.9444 - val_loss: 0.1867 - val_categorical_accuracy: 0.9442\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1823 - categorical_accuracy: 0.9447 - val_loss: 0.1857 - val_categorical_accuracy: 0.9439\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1817 - categorical_accuracy: 0.9447 - val_loss: 0.1860 - val_categorical_accuracy: 0.9443\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1809 - categorical_accuracy: 0.9447 - val_loss: 0.1847 - val_categorical_accuracy: 0.9452\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1803 - categorical_accuracy: 0.9454 - val_loss: 0.1844 - val_categorical_accuracy: 0.9448\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1794 - categorical_accuracy: 0.9454 - val_loss: 0.1834 - val_categorical_accuracy: 0.9453\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1787 - categorical_accuracy: 0.9460 - val_loss: 0.1832 - val_categorical_accuracy: 0.9453\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1781 - categorical_accuracy: 0.9457 - val_loss: 0.1829 - val_categorical_accuracy: 0.9453\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1774 - categorical_accuracy: 0.9461 - val_loss: 0.1820 - val_categorical_accuracy: 0.9454\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1766 - categorical_accuracy: 0.9462 - val_loss: 0.1824 - val_categorical_accuracy: 0.9453\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1759 - categorical_accuracy: 0.9466 - val_loss: 0.1815 - val_categorical_accuracy: 0.9451\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1752 - categorical_accuracy: 0.9467 - val_loss: 0.1805 - val_categorical_accuracy: 0.9458\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1745 - categorical_accuracy: 0.9469 - val_loss: 0.1803 - val_categorical_accuracy: 0.9467\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1740 - categorical_accuracy: 0.9471 - val_loss: 0.1801 - val_categorical_accuracy: 0.9453\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1733 - categorical_accuracy: 0.9471 - val_loss: 0.1788 - val_categorical_accuracy: 0.9463\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1726 - categorical_accuracy: 0.9476 - val_loss: 0.1788 - val_categorical_accuracy: 0.9465\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1719 - categorical_accuracy: 0.9474 - val_loss: 0.1787 - val_categorical_accuracy: 0.9465\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1713 - categorical_accuracy: 0.9480 - val_loss: 0.1775 - val_categorical_accuracy: 0.9466\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1707 - categorical_accuracy: 0.9480 - val_loss: 0.1777 - val_categorical_accuracy: 0.9471\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1701 - categorical_accuracy: 0.9484 - val_loss: 0.1771 - val_categorical_accuracy: 0.9478\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1695 - categorical_accuracy: 0.9484 - val_loss: 0.1763 - val_categorical_accuracy: 0.9472\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1687 - categorical_accuracy: 0.9487 - val_loss: 0.1755 - val_categorical_accuracy: 0.9477\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1681 - categorical_accuracy: 0.9486 - val_loss: 0.1752 - val_categorical_accuracy: 0.9476\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1675 - categorical_accuracy: 0.9489 - val_loss: 0.1753 - val_categorical_accuracy: 0.9473\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1669 - categorical_accuracy: 0.9489 - val_loss: 0.1751 - val_categorical_accuracy: 0.9480\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1664 - categorical_accuracy: 0.9486 - val_loss: 0.1738 - val_categorical_accuracy: 0.9483\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1659 - categorical_accuracy: 0.9496 - val_loss: 0.1739 - val_categorical_accuracy: 0.9485\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1652 - categorical_accuracy: 0.9498 - val_loss: 0.1732 - val_categorical_accuracy: 0.9481\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1646 - categorical_accuracy: 0.9504 - val_loss: 0.1727 - val_categorical_accuracy: 0.9483\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1642 - categorical_accuracy: 0.9503 - val_loss: 0.1730 - val_categorical_accuracy: 0.9492\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1636 - categorical_accuracy: 0.9505 - val_loss: 0.1723 - val_categorical_accuracy: 0.9487\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1631 - categorical_accuracy: 0.9507 - val_loss: 0.1719 - val_categorical_accuracy: 0.9485\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1624 - categorical_accuracy: 0.9505 - val_loss: 0.1707 - val_categorical_accuracy: 0.9492\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1620 - categorical_accuracy: 0.9507 - val_loss: 0.1709 - val_categorical_accuracy: 0.9488\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1614 - categorical_accuracy: 0.9509 - val_loss: 0.1701 - val_categorical_accuracy: 0.9497\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1610 - categorical_accuracy: 0.9512 - val_loss: 0.1695 - val_categorical_accuracy: 0.9496\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.1604 - categorical_accuracy: 0.9509 - val_loss: 0.1693 - val_categorical_accuracy: 0.9489\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1598 - categorical_accuracy: 0.9516 - val_loss: 0.1690 - val_categorical_accuracy: 0.9491\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.1592 - categorical_accuracy: 0.9515 - val_loss: 0.1683 - val_categorical_accuracy: 0.9500\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1587 - categorical_accuracy: 0.9518 - val_loss: 0.1687 - val_categorical_accuracy: 0.9488\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1582 - categorical_accuracy: 0.9518 - val_loss: 0.1679 - val_categorical_accuracy: 0.9495\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1579 - categorical_accuracy: 0.9521 - val_loss: 0.1676 - val_categorical_accuracy: 0.9497\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1572 - categorical_accuracy: 0.9526 - val_loss: 0.1677 - val_categorical_accuracy: 0.9498\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1568 - categorical_accuracy: 0.9526 - val_loss: 0.1663 - val_categorical_accuracy: 0.9504\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.1563 - categorical_accuracy: 0.9526 - val_loss: 0.1666 - val_categorical_accuracy: 0.9499\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1558 - categorical_accuracy: 0.9528 - val_loss: 0.1663 - val_categorical_accuracy: 0.9500\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1554 - categorical_accuracy: 0.9530 - val_loss: 0.1655 - val_categorical_accuracy: 0.9504\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1548 - categorical_accuracy: 0.9528 - val_loss: 0.1655 - val_categorical_accuracy: 0.9502\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1542 - categorical_accuracy: 0.9533 - val_loss: 0.1650 - val_categorical_accuracy: 0.9505\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1540 - categorical_accuracy: 0.9527 - val_loss: 0.1650 - val_categorical_accuracy: 0.9508\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1534 - categorical_accuracy: 0.9533 - val_loss: 0.1641 - val_categorical_accuracy: 0.9510\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1529 - categorical_accuracy: 0.9539 - val_loss: 0.1643 - val_categorical_accuracy: 0.9513\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1525 - categorical_accuracy: 0.9538 - val_loss: 0.1636 - val_categorical_accuracy: 0.9513\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1521 - categorical_accuracy: 0.9536 - val_loss: 0.1628 - val_categorical_accuracy: 0.9509\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.1516 - categorical_accuracy: 0.9544 - val_loss: 0.1624 - val_categorical_accuracy: 0.9510\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.1511 - categorical_accuracy: 0.9538 - val_loss: 0.1624 - val_categorical_accuracy: 0.9517\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1507 - categorical_accuracy: 0.9543 - val_loss: 0.1624 - val_categorical_accuracy: 0.9511\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1503 - categorical_accuracy: 0.9541 - val_loss: 0.1619 - val_categorical_accuracy: 0.9514\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1498 - categorical_accuracy: 0.9546 - val_loss: 0.1627 - val_categorical_accuracy: 0.9512\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1495 - categorical_accuracy: 0.9545 - val_loss: 0.1625 - val_categorical_accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(60000,49)\n",
    "X_test=X_test.reshape(10000,49)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(7*7,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n",
      "Test score: 0.14904760841466486\n",
      "Test accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance is not bad, albeit not as good as our previous attemptes having a deep network find features themselves. To better understand this: when training the network with the full 28x28 pixels, we are letting the network sift through 784 bytes of data to make a decision, which digit an input depicts. In particular, we have no idea what happens inside the network and what it actually ends up looking for. This is different when doing some of the pre-processing ourselves. Specifically, we decided that the majority of the information should be contained in whether a subset of 7x7 \"super-pixels\" are populated or not. We are then training on the reduced feature set that is represented by only 49 bytes - 16 times less.\n",
    "\n",
    "Albeit we might be able to hand-engineer better features than those chosen here, even some that are able to ultimately beat a brute-force neural network approach in terms of accuracy, machine learning has developed tools that have made hand-engineering features obsolete, rather take advantage of neural network architectures that in themselves perform preprocessing that are conducive to image and speech recognition. These are known as <i>convolutional neural networks</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal training parameters\n",
    "\n",
    "Albeit poking around with the different options of the variying machine learning toolkits is a lot easier than hand-coding features, and decisions can partly be informed by a fundamental understanding of the underlying methods (such as provided by this course), what works and what does not still heavily depends on the data actually at hand. For example, the \"batch size\" is a parameter for which only rough guidelines can be given. Often, playing with certain parameters or even systematically sweeping them can provide some intuition. For example, we can easily test the impact of different batch sizes, by training a model with a couple of different ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_sizes=[8,16,32,64,128,256,512]\n",
    "#batch_sizes=[128,256,512]\n",
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES,input_shape=(784,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['categorical_accuracy'])\n",
    "\n",
    "score=np.zeros((len(batch_sizes),2))\n",
    "times=np.zeros((len(batch_sizes),2))\n",
    "\n",
    "for I, batch_size in enumerate(batch_sizes):\n",
    "    t=time.time()\n",
    "    history = model.fit(X_train, Y_train,batch_size=batch_size, verbose=0, epochs=20, validation_split=VALIDATION_SPLIT)\n",
    "    score[I] = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    times[I] = time.time()-t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_sizes,score[:,1])\n",
    "plt.plot(batch_sizes,score[:,1],'*')\n",
    "plt.ylabel('Categorical accuracy')\n",
    "plt.xlabel('Batch size')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(batch_sizes,times)\n",
    "plt.plot(batch_sizes,times,'*')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.xlabel('Batch size')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above experiment, that the batch size actually has an optimum. If too low, the gradient jumps back and forth for every new training instance, if too high, the gradient combines too many experiences into one. We also observe, however, that training becomes exponentially slower with smaller batch sizes. It is therefore prudent to start with a reasonably large batch si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- Coding features by hand as much as possible has been the standard approach to design a machine learning algorithm for many decades. The idea has been that hand-coding leverages as much human expert knowledge as possible, while reducing the data sufficiently to make training a neural network actually tractable. \n",
    "- The ability to train also larger networks efficiently, has allowed to create \"deep\" neural networks that can get very good performance, sometimes even exceeding those of solutions relying on hand-coded features, without much tuning whatsoever.\n",
    "- We have slightly introduced a new feature, using a part of the test set for validation. This can help the training algorithm in many ways, for example detecting overfitting, stopping once a certain performance on valiation is met, and others.\n",
    "- Albeit the validation set can help to determine the optimal number of epochs, that is the number of times a dataset is presented to the network, the \"batch size\" remains a free parameter. If too low, weights are updated for every training instance, which is very susceptive to noise. If too high, the gradient is averaged over too many instances at once, ignoring possibly important information such as particularly salient examples.  \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
