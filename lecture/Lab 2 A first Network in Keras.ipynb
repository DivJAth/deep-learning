{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and training multi-layer artificial neural networks in Keras\n",
    "\n",
    "Fortunately, the past decade has resulted in a large number of tools to efficiently work with very large, so-called deep neural networks. Among the more prominent tools are <a href=\"https://en.wikipedia.org/wiki/Theano_(software)\">theano</a> and <a href=\"https://en.wikipedia.org/wiki/TensorFlow\">Tensorflow</a>, from the University of Montreal and Google Inc., respectively, and the <a href=\"https://en.wikipedia.org/wiki/Keras\">Keras</a> library to conveniently interface with them. We will be using Keras in this class to study the most important deep neural network architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a series of standard models, the simplest being a sequential model that allows the user to stack layers of artifical neurons together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_dim=3,kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example creates a sequential neural network with one \"dense\" layer with 2 artificial neurons, input dimension of 3, and uniformly random initial weights. Keras offers the following options <code>random_uniform</code>, <code>random_normal</code>, and <code>zero</code>, which are self-explanatory. Using a <i>dense</i> layer means that all inputs to a layer are connected to every neuron, and all outputs of a layer connect to all neurons of the next layer. The multi-layer perceptron shown above is a dense network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a first ANN\n",
    "\n",
    "Example from Antonio Gulli, “Deep Learning with Keras.” The MNIST data set is a collection of 70000 hand-written digits from 0 to 9 that are provided in a 28x28 matrix. The MNIST data set is part of the ```keras.datasets``` <a href=\"https://keras.io/datasets/\">library</a>. We will further import a simple ```Sequential``` model, creating a ```Dense``` model with custom ```Activation```, the ```SGD``` optimizer, which will be discussed later, and ```np_utils``` for One-Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "The following script will load the MNIST dataset (directly from the keras.datasets library) and turn the 28x28 training images into a series of one-dimensional vectors of length 784. We will also normalize the data to fall into the range from 0 to 1, and turn the class labels into one-hot encoded categorical labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# network and training\n",
    "\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "#\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "#\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the dataset using Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for I in range(4):\n",
    "    for J in range(4):\n",
    "        plt.subplot(4,4,I*4+J+1)\n",
    "        plt.imshow(X_train[I*4+J,:].reshape(28,28))\n",
    "plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "In a first step, we define a neural network with two layers: 10 neurons with 784 inputs and a softmax activation layer. As expected, this network has 7850 parameters, 10 times 784 for the weights and 10 for the bias values.\n",
    "\n",
    "In keras, a neural network model consists both of the architecture as well as a choice of an objective function, an optimizer, and a metrics. Note, that we are using <code>categorical_crossentropy</code>, which is more suited than <code>mean_squared_error</code> when calculating hte error between model prediction and training data. We are using stochastic gradient descent (SGD) as an optimizer, which is using data to estimate gradients vs. explicitely calculating the gradient as we have done before. The \"metrics\" parameter is similar to the objective function (\"loss\"), but is used when evaluating the model, not during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(784,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "After defining the model, the optimizer, the loss function and the metric for testing, training the model is a simple call to keras' <code>fit()</code> function. We are presenting the network with 200 instances of the entire dataset (\"epochs\") and perform a an update of the weights every 128 training samples (\"batch size\"). Setting <code>verbose</code> to 1 lets us see the progress, and using 0.2 (20%) of the dataset as <code>validation_split</code> lets us observe not only the model fit, but already how the model would perform on unknown data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 1.3633 - categorical_accuracy: 0.6796 - val_loss: 0.8904 - val_categorical_accuracy: 0.8246\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.7913 - categorical_accuracy: 0.8272 - val_loss: 0.6572 - val_categorical_accuracy: 0.8546\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.6436 - categorical_accuracy: 0.8497 - val_loss: 0.5625 - val_categorical_accuracy: 0.8681\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.5717 - categorical_accuracy: 0.8602 - val_loss: 0.5098 - val_categorical_accuracy: 0.8765\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.5276 - categorical_accuracy: 0.8678 - val_loss: 0.4758 - val_categorical_accuracy: 0.8826\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4973 - categorical_accuracy: 0.8726 - val_loss: 0.4515 - val_categorical_accuracy: 0.8866\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4748 - categorical_accuracy: 0.8775 - val_loss: 0.4333 - val_categorical_accuracy: 0.8882\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4574 - categorical_accuracy: 0.8803 - val_loss: 0.4189 - val_categorical_accuracy: 0.8920\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4433 - categorical_accuracy: 0.8834 - val_loss: 0.4075 - val_categorical_accuracy: 0.8939\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4317 - categorical_accuracy: 0.8850 - val_loss: 0.3977 - val_categorical_accuracy: 0.8966\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4218 - categorical_accuracy: 0.8873 - val_loss: 0.3896 - val_categorical_accuracy: 0.8984\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4134 - categorical_accuracy: 0.8888 - val_loss: 0.3827 - val_categorical_accuracy: 0.8995\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4060 - categorical_accuracy: 0.8902 - val_loss: 0.3766 - val_categorical_accuracy: 0.9003\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3995 - categorical_accuracy: 0.8918 - val_loss: 0.3712 - val_categorical_accuracy: 0.9013\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3936 - categorical_accuracy: 0.8928 - val_loss: 0.3664 - val_categorical_accuracy: 0.9016\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3884 - categorical_accuracy: 0.8945 - val_loss: 0.3621 - val_categorical_accuracy: 0.9031\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3837 - categorical_accuracy: 0.8950 - val_loss: 0.3582 - val_categorical_accuracy: 0.9033\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3794 - categorical_accuracy: 0.8962 - val_loss: 0.3546 - val_categorical_accuracy: 0.9039\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3755 - categorical_accuracy: 0.8970 - val_loss: 0.3514 - val_categorical_accuracy: 0.9048\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3718 - categorical_accuracy: 0.8979 - val_loss: 0.3485 - val_categorical_accuracy: 0.9053\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3685 - categorical_accuracy: 0.8985 - val_loss: 0.3457 - val_categorical_accuracy: 0.9058\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3653 - categorical_accuracy: 0.8995 - val_loss: 0.3431 - val_categorical_accuracy: 0.9058\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3625 - categorical_accuracy: 0.8999 - val_loss: 0.3407 - val_categorical_accuracy: 0.9063\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3598 - categorical_accuracy: 0.9008 - val_loss: 0.3385 - val_categorical_accuracy: 0.9070\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3572 - categorical_accuracy: 0.9012 - val_loss: 0.3364 - val_categorical_accuracy: 0.9074\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3548 - categorical_accuracy: 0.9019 - val_loss: 0.3345 - val_categorical_accuracy: 0.9084\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3525 - categorical_accuracy: 0.9022 - val_loss: 0.3326 - val_categorical_accuracy: 0.9082\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3504 - categorical_accuracy: 0.9032 - val_loss: 0.3311 - val_categorical_accuracy: 0.9090\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3484 - categorical_accuracy: 0.9031 - val_loss: 0.3293 - val_categorical_accuracy: 0.9094\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3465 - categorical_accuracy: 0.9041 - val_loss: 0.3277 - val_categorical_accuracy: 0.9097\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3447 - categorical_accuracy: 0.9044 - val_loss: 0.3264 - val_categorical_accuracy: 0.9097\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3430 - categorical_accuracy: 0.9047 - val_loss: 0.3249 - val_categorical_accuracy: 0.9097\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3413 - categorical_accuracy: 0.9051 - val_loss: 0.3235 - val_categorical_accuracy: 0.9103\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3397 - categorical_accuracy: 0.9056 - val_loss: 0.3222 - val_categorical_accuracy: 0.9104\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3382 - categorical_accuracy: 0.9058 - val_loss: 0.3211 - val_categorical_accuracy: 0.9110\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3368 - categorical_accuracy: 0.9062 - val_loss: 0.3198 - val_categorical_accuracy: 0.9110\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3353 - categorical_accuracy: 0.9069 - val_loss: 0.3187 - val_categorical_accuracy: 0.9117\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3340 - categorical_accuracy: 0.9075 - val_loss: 0.3177 - val_categorical_accuracy: 0.9120\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3327 - categorical_accuracy: 0.9075 - val_loss: 0.3166 - val_categorical_accuracy: 0.9122\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3314 - categorical_accuracy: 0.9078 - val_loss: 0.3159 - val_categorical_accuracy: 0.9118\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3303 - categorical_accuracy: 0.9080 - val_loss: 0.3147 - val_categorical_accuracy: 0.9127\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3291 - categorical_accuracy: 0.9084 - val_loss: 0.3138 - val_categorical_accuracy: 0.9132\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3280 - categorical_accuracy: 0.9089 - val_loss: 0.3130 - val_categorical_accuracy: 0.9132\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3270 - categorical_accuracy: 0.9091 - val_loss: 0.3121 - val_categorical_accuracy: 0.9132\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3259 - categorical_accuracy: 0.9093 - val_loss: 0.3113 - val_categorical_accuracy: 0.9135\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3249 - categorical_accuracy: 0.9095 - val_loss: 0.3105 - val_categorical_accuracy: 0.9137\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3239 - categorical_accuracy: 0.9105 - val_loss: 0.3098 - val_categorical_accuracy: 0.9141\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3230 - categorical_accuracy: 0.9105 - val_loss: 0.3090 - val_categorical_accuracy: 0.9146\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3221 - categorical_accuracy: 0.9102 - val_loss: 0.3083 - val_categorical_accuracy: 0.9151\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3212 - categorical_accuracy: 0.9109 - val_loss: 0.3075 - val_categorical_accuracy: 0.9150\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3204 - categorical_accuracy: 0.9109 - val_loss: 0.3070 - val_categorical_accuracy: 0.9150\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3195 - categorical_accuracy: 0.9112 - val_loss: 0.3063 - val_categorical_accuracy: 0.9148\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3187 - categorical_accuracy: 0.9114 - val_loss: 0.3057 - val_categorical_accuracy: 0.9153\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3180 - categorical_accuracy: 0.9117 - val_loss: 0.3050 - val_categorical_accuracy: 0.9148\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3171 - categorical_accuracy: 0.9121 - val_loss: 0.3044 - val_categorical_accuracy: 0.9149\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3164 - categorical_accuracy: 0.9121 - val_loss: 0.3037 - val_categorical_accuracy: 0.9156\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3157 - categorical_accuracy: 0.9128 - val_loss: 0.3034 - val_categorical_accuracy: 0.9152\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3149 - categorical_accuracy: 0.9121 - val_loss: 0.3029 - val_categorical_accuracy: 0.9148\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3143 - categorical_accuracy: 0.9128 - val_loss: 0.3022 - val_categorical_accuracy: 0.9151\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3136 - categorical_accuracy: 0.9129 - val_loss: 0.3016 - val_categorical_accuracy: 0.9161\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3130 - categorical_accuracy: 0.9133 - val_loss: 0.3011 - val_categorical_accuracy: 0.9158\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3123 - categorical_accuracy: 0.9131 - val_loss: 0.3007 - val_categorical_accuracy: 0.9151\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3117 - categorical_accuracy: 0.9136 - val_loss: 0.3003 - val_categorical_accuracy: 0.9156\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3110 - categorical_accuracy: 0.9137 - val_loss: 0.2997 - val_categorical_accuracy: 0.9158\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3105 - categorical_accuracy: 0.9137 - val_loss: 0.2992 - val_categorical_accuracy: 0.9159\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3098 - categorical_accuracy: 0.9138 - val_loss: 0.2988 - val_categorical_accuracy: 0.9161\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3093 - categorical_accuracy: 0.9141 - val_loss: 0.2983 - val_categorical_accuracy: 0.9165\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3087 - categorical_accuracy: 0.9139 - val_loss: 0.2979 - val_categorical_accuracy: 0.9166\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3082 - categorical_accuracy: 0.9144 - val_loss: 0.2976 - val_categorical_accuracy: 0.9164\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3077 - categorical_accuracy: 0.9145 - val_loss: 0.2971 - val_categorical_accuracy: 0.9166\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3071 - categorical_accuracy: 0.9146 - val_loss: 0.2967 - val_categorical_accuracy: 0.9172\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3066 - categorical_accuracy: 0.9147 - val_loss: 0.2964 - val_categorical_accuracy: 0.9167\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3061 - categorical_accuracy: 0.9151 - val_loss: 0.2960 - val_categorical_accuracy: 0.9169\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3056 - categorical_accuracy: 0.9150 - val_loss: 0.2956 - val_categorical_accuracy: 0.9173\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3051 - categorical_accuracy: 0.9151 - val_loss: 0.2952 - val_categorical_accuracy: 0.9177\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3046 - categorical_accuracy: 0.9152 - val_loss: 0.2950 - val_categorical_accuracy: 0.9173\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3042 - categorical_accuracy: 0.9154 - val_loss: 0.2945 - val_categorical_accuracy: 0.9172\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3037 - categorical_accuracy: 0.9154 - val_loss: 0.2942 - val_categorical_accuracy: 0.9176\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3032 - categorical_accuracy: 0.9157 - val_loss: 0.2939 - val_categorical_accuracy: 0.9179\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3028 - categorical_accuracy: 0.9156 - val_loss: 0.2936 - val_categorical_accuracy: 0.9177\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3024 - categorical_accuracy: 0.9157 - val_loss: 0.2933 - val_categorical_accuracy: 0.9179\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3019 - categorical_accuracy: 0.9157 - val_loss: 0.2930 - val_categorical_accuracy: 0.9178\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3015 - categorical_accuracy: 0.9160 - val_loss: 0.2926 - val_categorical_accuracy: 0.9182\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3011 - categorical_accuracy: 0.9161 - val_loss: 0.2924 - val_categorical_accuracy: 0.9179\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3007 - categorical_accuracy: 0.9165 - val_loss: 0.2920 - val_categorical_accuracy: 0.9184\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3003 - categorical_accuracy: 0.9164 - val_loss: 0.2918 - val_categorical_accuracy: 0.9185\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2999 - categorical_accuracy: 0.9165 - val_loss: 0.2914 - val_categorical_accuracy: 0.9185\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2995 - categorical_accuracy: 0.9166 - val_loss: 0.2911 - val_categorical_accuracy: 0.9188\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2991 - categorical_accuracy: 0.9167 - val_loss: 0.2909 - val_categorical_accuracy: 0.9191\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2988 - categorical_accuracy: 0.9169 - val_loss: 0.2906 - val_categorical_accuracy: 0.9191\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2984 - categorical_accuracy: 0.9168 - val_loss: 0.2903 - val_categorical_accuracy: 0.9192\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2981 - categorical_accuracy: 0.9170 - val_loss: 0.2901 - val_categorical_accuracy: 0.9196\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2977 - categorical_accuracy: 0.9171 - val_loss: 0.2898 - val_categorical_accuracy: 0.9195\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2973 - categorical_accuracy: 0.9172 - val_loss: 0.2895 - val_categorical_accuracy: 0.9196\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2970 - categorical_accuracy: 0.9174 - val_loss: 0.2894 - val_categorical_accuracy: 0.9196\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2967 - categorical_accuracy: 0.9174 - val_loss: 0.2891 - val_categorical_accuracy: 0.9198\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2963 - categorical_accuracy: 0.9176 - val_loss: 0.2889 - val_categorical_accuracy: 0.9197\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2960 - categorical_accuracy: 0.9174 - val_loss: 0.2886 - val_categorical_accuracy: 0.9202\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2957 - categorical_accuracy: 0.9176 - val_loss: 0.2884 - val_categorical_accuracy: 0.9202\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2953 - categorical_accuracy: 0.9178 - val_loss: 0.2882 - val_categorical_accuracy: 0.9200\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2950 - categorical_accuracy: 0.9179 - val_loss: 0.2879 - val_categorical_accuracy: 0.9201\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2947 - categorical_accuracy: 0.9180 - val_loss: 0.2877 - val_categorical_accuracy: 0.9204\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2944 - categorical_accuracy: 0.9180 - val_loss: 0.2875 - val_categorical_accuracy: 0.9202\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2941 - categorical_accuracy: 0.9184 - val_loss: 0.2873 - val_categorical_accuracy: 0.9202\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2938 - categorical_accuracy: 0.9183 - val_loss: 0.2871 - val_categorical_accuracy: 0.9206\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2935 - categorical_accuracy: 0.9183 - val_loss: 0.2868 - val_categorical_accuracy: 0.9202\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2932 - categorical_accuracy: 0.9186 - val_loss: 0.2867 - val_categorical_accuracy: 0.9206\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2929 - categorical_accuracy: 0.9185 - val_loss: 0.2864 - val_categorical_accuracy: 0.9208\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2927 - categorical_accuracy: 0.9185 - val_loss: 0.2863 - val_categorical_accuracy: 0.9206\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2923 - categorical_accuracy: 0.9187 - val_loss: 0.2860 - val_categorical_accuracy: 0.9204\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2921 - categorical_accuracy: 0.9184 - val_loss: 0.2858 - val_categorical_accuracy: 0.9210\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2918 - categorical_accuracy: 0.9187 - val_loss: 0.2857 - val_categorical_accuracy: 0.9207\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2915 - categorical_accuracy: 0.9189 - val_loss: 0.2854 - val_categorical_accuracy: 0.9210\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2913 - categorical_accuracy: 0.9188 - val_loss: 0.2853 - val_categorical_accuracy: 0.9211\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2910 - categorical_accuracy: 0.9189 - val_loss: 0.2852 - val_categorical_accuracy: 0.9205\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2908 - categorical_accuracy: 0.9189 - val_loss: 0.2849 - val_categorical_accuracy: 0.9213\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2905 - categorical_accuracy: 0.9193 - val_loss: 0.2847 - val_categorical_accuracy: 0.9213\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2902 - categorical_accuracy: 0.9192 - val_loss: 0.2846 - val_categorical_accuracy: 0.9212\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2900 - categorical_accuracy: 0.9191 - val_loss: 0.2844 - val_categorical_accuracy: 0.9212\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2898 - categorical_accuracy: 0.9192 - val_loss: 0.2842 - val_categorical_accuracy: 0.9212\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2895 - categorical_accuracy: 0.9191 - val_loss: 0.2841 - val_categorical_accuracy: 0.9212\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2892 - categorical_accuracy: 0.9192 - val_loss: 0.2840 - val_categorical_accuracy: 0.9212\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2890 - categorical_accuracy: 0.9194 - val_loss: 0.2838 - val_categorical_accuracy: 0.9211\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2888 - categorical_accuracy: 0.9197 - val_loss: 0.2837 - val_categorical_accuracy: 0.9210\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2885 - categorical_accuracy: 0.9193 - val_loss: 0.2835 - val_categorical_accuracy: 0.9207\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2883 - categorical_accuracy: 0.9197 - val_loss: 0.2834 - val_categorical_accuracy: 0.9217\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2881 - categorical_accuracy: 0.9194 - val_loss: 0.2832 - val_categorical_accuracy: 0.9212\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2879 - categorical_accuracy: 0.9194 - val_loss: 0.2830 - val_categorical_accuracy: 0.9210\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2876 - categorical_accuracy: 0.9196 - val_loss: 0.2828 - val_categorical_accuracy: 0.9217\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2874 - categorical_accuracy: 0.9197 - val_loss: 0.2826 - val_categorical_accuracy: 0.9216\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2871 - categorical_accuracy: 0.9200 - val_loss: 0.2827 - val_categorical_accuracy: 0.9211\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2870 - categorical_accuracy: 0.9197 - val_loss: 0.2824 - val_categorical_accuracy: 0.9213\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2868 - categorical_accuracy: 0.9198 - val_loss: 0.2823 - val_categorical_accuracy: 0.9216\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2866 - categorical_accuracy: 0.9199 - val_loss: 0.2822 - val_categorical_accuracy: 0.9214\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2863 - categorical_accuracy: 0.9203 - val_loss: 0.2820 - val_categorical_accuracy: 0.9213\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2861 - categorical_accuracy: 0.9196 - val_loss: 0.2818 - val_categorical_accuracy: 0.9215\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2859 - categorical_accuracy: 0.9198 - val_loss: 0.2818 - val_categorical_accuracy: 0.9217\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2857 - categorical_accuracy: 0.9203 - val_loss: 0.2815 - val_categorical_accuracy: 0.9218\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2855 - categorical_accuracy: 0.9203 - val_loss: 0.2814 - val_categorical_accuracy: 0.9215\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2853 - categorical_accuracy: 0.9201 - val_loss: 0.2812 - val_categorical_accuracy: 0.9216\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2852 - categorical_accuracy: 0.9204 - val_loss: 0.2811 - val_categorical_accuracy: 0.9217\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2849 - categorical_accuracy: 0.9201 - val_loss: 0.2810 - val_categorical_accuracy: 0.9217\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2848 - categorical_accuracy: 0.9205 - val_loss: 0.2809 - val_categorical_accuracy: 0.9219\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2846 - categorical_accuracy: 0.9208 - val_loss: 0.2808 - val_categorical_accuracy: 0.9217\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2844 - categorical_accuracy: 0.9207 - val_loss: 0.2806 - val_categorical_accuracy: 0.9221\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2841 - categorical_accuracy: 0.9206 - val_loss: 0.2806 - val_categorical_accuracy: 0.9220\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2840 - categorical_accuracy: 0.9207 - val_loss: 0.2804 - val_categorical_accuracy: 0.9217\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2838 - categorical_accuracy: 0.9209 - val_loss: 0.2803 - val_categorical_accuracy: 0.9218\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2836 - categorical_accuracy: 0.9208 - val_loss: 0.2802 - val_categorical_accuracy: 0.9216\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2835 - categorical_accuracy: 0.9210 - val_loss: 0.2800 - val_categorical_accuracy: 0.9225\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2833 - categorical_accuracy: 0.9210 - val_loss: 0.2799 - val_categorical_accuracy: 0.9226\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2831 - categorical_accuracy: 0.9211 - val_loss: 0.2798 - val_categorical_accuracy: 0.9222\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2829 - categorical_accuracy: 0.9207 - val_loss: 0.2797 - val_categorical_accuracy: 0.9224\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2827 - categorical_accuracy: 0.9209 - val_loss: 0.2796 - val_categorical_accuracy: 0.9222\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2826 - categorical_accuracy: 0.9208 - val_loss: 0.2795 - val_categorical_accuracy: 0.9225\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2824 - categorical_accuracy: 0.9210 - val_loss: 0.2794 - val_categorical_accuracy: 0.9224\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2822 - categorical_accuracy: 0.9210 - val_loss: 0.2793 - val_categorical_accuracy: 0.9224\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2821 - categorical_accuracy: 0.9214 - val_loss: 0.2792 - val_categorical_accuracy: 0.9226\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2819 - categorical_accuracy: 0.9214 - val_loss: 0.2791 - val_categorical_accuracy: 0.9226\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2817 - categorical_accuracy: 0.9213 - val_loss: 0.2790 - val_categorical_accuracy: 0.9225\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2816 - categorical_accuracy: 0.9214 - val_loss: 0.2789 - val_categorical_accuracy: 0.9222\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2814 - categorical_accuracy: 0.9215 - val_loss: 0.2788 - val_categorical_accuracy: 0.9227\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2812 - categorical_accuracy: 0.9213 - val_loss: 0.2787 - val_categorical_accuracy: 0.9225\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2811 - categorical_accuracy: 0.9216 - val_loss: 0.2786 - val_categorical_accuracy: 0.9225\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2809 - categorical_accuracy: 0.9215 - val_loss: 0.2785 - val_categorical_accuracy: 0.9227\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2807 - categorical_accuracy: 0.9216 - val_loss: 0.2784 - val_categorical_accuracy: 0.9225\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2806 - categorical_accuracy: 0.9217 - val_loss: 0.2784 - val_categorical_accuracy: 0.9227\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2804 - categorical_accuracy: 0.9219 - val_loss: 0.2782 - val_categorical_accuracy: 0.9228\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2803 - categorical_accuracy: 0.9216 - val_loss: 0.2782 - val_categorical_accuracy: 0.9227\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2801 - categorical_accuracy: 0.9216 - val_loss: 0.2781 - val_categorical_accuracy: 0.9227\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2800 - categorical_accuracy: 0.9220 - val_loss: 0.2780 - val_categorical_accuracy: 0.9226\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2798 - categorical_accuracy: 0.9218 - val_loss: 0.2778 - val_categorical_accuracy: 0.9231\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2797 - categorical_accuracy: 0.9217 - val_loss: 0.2778 - val_categorical_accuracy: 0.9229\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2796 - categorical_accuracy: 0.9217 - val_loss: 0.2777 - val_categorical_accuracy: 0.9227\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2794 - categorical_accuracy: 0.9218 - val_loss: 0.2776 - val_categorical_accuracy: 0.9232\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2793 - categorical_accuracy: 0.9220 - val_loss: 0.2775 - val_categorical_accuracy: 0.9232\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2791 - categorical_accuracy: 0.9219 - val_loss: 0.2774 - val_categorical_accuracy: 0.9234\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2790 - categorical_accuracy: 0.9221 - val_loss: 0.2774 - val_categorical_accuracy: 0.9228\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2788 - categorical_accuracy: 0.9221 - val_loss: 0.2773 - val_categorical_accuracy: 0.9232\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2787 - categorical_accuracy: 0.9221 - val_loss: 0.2771 - val_categorical_accuracy: 0.9235\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2785 - categorical_accuracy: 0.9223 - val_loss: 0.2770 - val_categorical_accuracy: 0.9232\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2784 - categorical_accuracy: 0.9220 - val_loss: 0.2769 - val_categorical_accuracy: 0.9231\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2783 - categorical_accuracy: 0.9223 - val_loss: 0.2769 - val_categorical_accuracy: 0.9231\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2781 - categorical_accuracy: 0.9223 - val_loss: 0.2768 - val_categorical_accuracy: 0.9230\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2780 - categorical_accuracy: 0.9224 - val_loss: 0.2767 - val_categorical_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2779 - categorical_accuracy: 0.9223 - val_loss: 0.2766 - val_categorical_accuracy: 0.9236\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2777 - categorical_accuracy: 0.9224 - val_loss: 0.2766 - val_categorical_accuracy: 0.9233\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2776 - categorical_accuracy: 0.9226 - val_loss: 0.2765 - val_categorical_accuracy: 0.9236\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2775 - categorical_accuracy: 0.9225 - val_loss: 0.2764 - val_categorical_accuracy: 0.9235\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2773 - categorical_accuracy: 0.9225 - val_loss: 0.2764 - val_categorical_accuracy: 0.9235\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2772 - categorical_accuracy: 0.9225 - val_loss: 0.2763 - val_categorical_accuracy: 0.9237\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2770 - categorical_accuracy: 0.9226 - val_loss: 0.2762 - val_categorical_accuracy: 0.9238\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2770 - categorical_accuracy: 0.9226 - val_loss: 0.2761 - val_categorical_accuracy: 0.9237\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2768 - categorical_accuracy: 0.9226 - val_loss: 0.2761 - val_categorical_accuracy: 0.9236\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2767 - categorical_accuracy: 0.9231 - val_loss: 0.2760 - val_categorical_accuracy: 0.9239\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2766 - categorical_accuracy: 0.9226 - val_loss: 0.2758 - val_categorical_accuracy: 0.9241\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2765 - categorical_accuracy: 0.9229 - val_loss: 0.2758 - val_categorical_accuracy: 0.9242\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2763 - categorical_accuracy: 0.9231 - val_loss: 0.2758 - val_categorical_accuracy: 0.9236\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2762 - categorical_accuracy: 0.9229 - val_loss: 0.2757 - val_categorical_accuracy: 0.9241\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2761 - categorical_accuracy: 0.9230 - val_loss: 0.2756 - val_categorical_accuracy: 0.9241\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=200, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Test score: 0.2773858499318361\n",
      "Test accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 92.27% on the test set sounds great, and that this can be achieved using only 7850 parameters - which after all encode all the knowledge about the dataset - is impressive. Yet, misclassifying every tenth digit is of little practical relevance. In fact, even 99.9% would mean that one out of a thousand digits is misread. When using such a network to identify the zip code on a letter, every 200th letter, on average, would be subject to a wrong reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing model complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase the complexity of the model by adding hidden layers. For example, adding two hidden layers with 128 neurons each, increases the number of parameters to 118,282. In this case, we can obtain a test accuracy of 97.61%. You can further increase model complexity, for example by employing 1280 hidden nodes, resulting in more than 2.6M parameters. This will allow you to exceed 99% on training accuracy, but not much more than 98% on the test. At some point, you will learn an exact representation of the training data, even 100% accuracy on the training set, but not be able to train a network that is able to truly understand what to look for in your data. This is known as <i>overfitting</i>. As a rule of thumb, a network should always be trained so that the accuracy of training exceeds that of the test set, but not too much further as the reason is likely overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH=200\n",
    "BATCH_SIZE=128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes='true', to_file='figs/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to render the neural network graphically using Keras' <code>plot_model</code> module (see above)\n",
    "\n",
    "<center>\n",
    "<img src=\"figs/model.png\" width=\"30%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 1.4342 - categorical_accuracy: 0.6390 - val_loss: 0.7003 - val_categorical_accuracy: 0.8442\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.5690 - categorical_accuracy: 0.8573 - val_loss: 0.4317 - val_categorical_accuracy: 0.8867\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.4232 - categorical_accuracy: 0.8845 - val_loss: 0.3578 - val_categorical_accuracy: 0.9022\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.3675 - categorical_accuracy: 0.8974 - val_loss: 0.3248 - val_categorical_accuracy: 0.9089\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.3350 - categorical_accuracy: 0.9052 - val_loss: 0.2997 - val_categorical_accuracy: 0.9160\n",
      "Epoch 6/200\n",
      "30464/48000 [==================>...........] - ETA: 0s - loss: 0.3129 - categorical_accuracy: 0.9113"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7e823d4587b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train, Y_train,\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m verbose=1, validation_split=0.2)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5226\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5227\u001b[0m       with super(_DefaultGraphStack, self).get_controller(\n\u001b[0;32m-> 5228\u001b[0;31m           default) as g, context.graph_mode():\n\u001b[0m\u001b[1;32m   5229\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5230\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mold_is_eager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;31m# Entering graph mode does not provide us with sufficient information to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=1, validation_split=0.2)\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training history is available via Keras' <code>history</code> object. Its a dictionary with the following keys (this depends on how the model was compiled). It is particularly helpful to observe where training and test accuracy start to diverge, which is the point at which further training does not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x126436400>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'][:50])\n",
    "plt.plot(history.history['val_categorical_accuracy'][:50])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Categorical accuracy')\n",
    "plt.legend(['Training','Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving network performance (the old way)\n",
    "\n",
    "We note that all training so far has been done on the raw 28x28 bytes data. Furthermore, the 2D input data has been turned into a column vector leaving it up to the network to cherry-pick the salient information. In classic machine learning this has never been done. Instead, the trick has always been to carefully engineer features that both reduce the amount of data the network has to deal with and integrate human expert knowledge as best as possible.\n",
    "\n",
    "Looking at the MNIST data, there are many ideas that come to mind. For example, we might use basic image statistics to generate a first set of features. These could be the percentage of the matrix actually covered by pixels (with the numbers 8 and 9 using more pixels than the number 1, e.g.), the \"center of mass\" of the images with some numbers like 1 and 8 having a center of mass closer to the center and so on.\n",
    "\n",
    "We can also convolve the image with a Sobel-like filter to detect edges. Finally, we could downsample the image by grouping pixels into groups of 4x4 or even 7x7, and thresholding them. Here, the idea would be that presence of data in the new 16 or 49 \"super-pixels\" would actually suffice to classify the digits. \n",
    "\n",
    "Here, we first convolve the image with an edge detection kernel, then downsample it to a 7x7 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import signal\n",
    "from skimage.transform import downscale_local_mean # scikit-image\n",
    "\n",
    "(X_train_orig, y_train), (X_test_orig, y_test) = mnist.load_data()\n",
    "X_train=np.zeros((60000,7,7))\n",
    "X_test=np.zeros((10000,7,7))\n",
    "\n",
    "for I in range(X_train.shape[0]):\n",
    "    X_train[I]=downscale_local_mean(signal.convolve2d(X_train_orig[I,:,:]/255,[[-1,-1,-1],[-1,-8,-1],[-1,-1,-1]],mode='valid'),(4,4))\n",
    "    X_train[I]/=X_train[I].min() # values are negative after convolution\n",
    "\n",
    "for I in range(X_test.shape[0]):\n",
    "    X_test[I]=downscale_local_mean(signal.convolve2d(X_test_orig[I,:,:]/255,[[-1,-1,-1],[-1,-8,-1],[-1,-1,-1]],mode='valid'),(4,4))\n",
    "    X_test[I]/=X_test[I].min()\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for I in range(4):\n",
    "    for J in range(4):\n",
    "        plt.subplot(4,4,I*4+J+1)\n",
    "        plt.imshow(X_train[I*4+J,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 100)               5000      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,010\n",
      "Trainable params: 6,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 2.0864 - categorical_accuracy: 0.4040 - val_loss: 1.8903 - val_categorical_accuracy: 0.6118\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 1.7164 - categorical_accuracy: 0.6621 - val_loss: 1.5237 - val_categorical_accuracy: 0.7340\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 1.3858 - categorical_accuracy: 0.7418 - val_loss: 1.2200 - val_categorical_accuracy: 0.7856\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 1.1316 - categorical_accuracy: 0.7783 - val_loss: 1.0033 - val_categorical_accuracy: 0.8095\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.9562 - categorical_accuracy: 0.7999 - val_loss: 0.8575 - val_categorical_accuracy: 0.8287\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.8376 - categorical_accuracy: 0.8153 - val_loss: 0.7582 - val_categorical_accuracy: 0.8395\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.7555 - categorical_accuracy: 0.8250 - val_loss: 0.6887 - val_categorical_accuracy: 0.8478\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.6964 - categorical_accuracy: 0.8327 - val_loss: 0.6376 - val_categorical_accuracy: 0.8539\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.6521 - categorical_accuracy: 0.8373 - val_loss: 0.5993 - val_categorical_accuracy: 0.8553\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.6178 - categorical_accuracy: 0.8415 - val_loss: 0.5685 - val_categorical_accuracy: 0.8600\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5904 - categorical_accuracy: 0.8450 - val_loss: 0.5446 - val_categorical_accuracy: 0.8625\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5679 - categorical_accuracy: 0.8474 - val_loss: 0.5243 - val_categorical_accuracy: 0.8645\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5491 - categorical_accuracy: 0.8505 - val_loss: 0.5072 - val_categorical_accuracy: 0.8685\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5331 - categorical_accuracy: 0.8533 - val_loss: 0.4930 - val_categorical_accuracy: 0.8698\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5194 - categorical_accuracy: 0.8545 - val_loss: 0.4805 - val_categorical_accuracy: 0.8706\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.5072 - categorical_accuracy: 0.8569 - val_loss: 0.4695 - val_categorical_accuracy: 0.8733\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4966 - categorical_accuracy: 0.8594 - val_loss: 0.4600 - val_categorical_accuracy: 0.8748\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4869 - categorical_accuracy: 0.8608 - val_loss: 0.4510 - val_categorical_accuracy: 0.8757\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4783 - categorical_accuracy: 0.8626 - val_loss: 0.4435 - val_categorical_accuracy: 0.8759\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4705 - categorical_accuracy: 0.8640 - val_loss: 0.4362 - val_categorical_accuracy: 0.8775\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4632 - categorical_accuracy: 0.8655 - val_loss: 0.4296 - val_categorical_accuracy: 0.8791\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4565 - categorical_accuracy: 0.8673 - val_loss: 0.4237 - val_categorical_accuracy: 0.8793\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4503 - categorical_accuracy: 0.8691 - val_loss: 0.4181 - val_categorical_accuracy: 0.8807\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4445 - categorical_accuracy: 0.8702 - val_loss: 0.4131 - val_categorical_accuracy: 0.8840\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4390 - categorical_accuracy: 0.8715 - val_loss: 0.4081 - val_categorical_accuracy: 0.8846\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4339 - categorical_accuracy: 0.8725 - val_loss: 0.4034 - val_categorical_accuracy: 0.8855\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4291 - categorical_accuracy: 0.8735 - val_loss: 0.3992 - val_categorical_accuracy: 0.8871\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4245 - categorical_accuracy: 0.8748 - val_loss: 0.3949 - val_categorical_accuracy: 0.8877\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4201 - categorical_accuracy: 0.8757 - val_loss: 0.3911 - val_categorical_accuracy: 0.8885\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4159 - categorical_accuracy: 0.8765 - val_loss: 0.3874 - val_categorical_accuracy: 0.8902\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4119 - categorical_accuracy: 0.8778 - val_loss: 0.3840 - val_categorical_accuracy: 0.8905\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4082 - categorical_accuracy: 0.8793 - val_loss: 0.3806 - val_categorical_accuracy: 0.8918\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4045 - categorical_accuracy: 0.8796 - val_loss: 0.3774 - val_categorical_accuracy: 0.8929\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4009 - categorical_accuracy: 0.8807 - val_loss: 0.3741 - val_categorical_accuracy: 0.8935\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.3976 - categorical_accuracy: 0.8813 - val_loss: 0.3712 - val_categorical_accuracy: 0.8940\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3943 - categorical_accuracy: 0.8827 - val_loss: 0.3680 - val_categorical_accuracy: 0.8940\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3911 - categorical_accuracy: 0.8833 - val_loss: 0.3652 - val_categorical_accuracy: 0.8949\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3881 - categorical_accuracy: 0.8841 - val_loss: 0.3628 - val_categorical_accuracy: 0.8952\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3851 - categorical_accuracy: 0.8845 - val_loss: 0.3597 - val_categorical_accuracy: 0.8965\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3822 - categorical_accuracy: 0.8855 - val_loss: 0.3574 - val_categorical_accuracy: 0.8973\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3794 - categorical_accuracy: 0.8861 - val_loss: 0.3551 - val_categorical_accuracy: 0.8974\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3768 - categorical_accuracy: 0.8869 - val_loss: 0.3523 - val_categorical_accuracy: 0.8990\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3741 - categorical_accuracy: 0.8873 - val_loss: 0.3500 - val_categorical_accuracy: 0.8992\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3715 - categorical_accuracy: 0.8880 - val_loss: 0.3477 - val_categorical_accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3691 - categorical_accuracy: 0.8889 - val_loss: 0.3455 - val_categorical_accuracy: 0.8996\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3666 - categorical_accuracy: 0.8898 - val_loss: 0.3437 - val_categorical_accuracy: 0.9002\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3643 - categorical_accuracy: 0.8903 - val_loss: 0.3414 - val_categorical_accuracy: 0.9008\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3619 - categorical_accuracy: 0.8911 - val_loss: 0.3393 - val_categorical_accuracy: 0.9017\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3597 - categorical_accuracy: 0.8915 - val_loss: 0.3373 - val_categorical_accuracy: 0.9023\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3575 - categorical_accuracy: 0.8918 - val_loss: 0.3352 - val_categorical_accuracy: 0.9032\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3553 - categorical_accuracy: 0.8930 - val_loss: 0.3333 - val_categorical_accuracy: 0.9033\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3533 - categorical_accuracy: 0.8932 - val_loss: 0.3315 - val_categorical_accuracy: 0.9038\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3513 - categorical_accuracy: 0.8938 - val_loss: 0.3298 - val_categorical_accuracy: 0.9041\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3493 - categorical_accuracy: 0.8943 - val_loss: 0.3279 - val_categorical_accuracy: 0.9046\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3473 - categorical_accuracy: 0.8950 - val_loss: 0.3263 - val_categorical_accuracy: 0.9056\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3455 - categorical_accuracy: 0.8959 - val_loss: 0.3246 - val_categorical_accuracy: 0.9061\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3436 - categorical_accuracy: 0.8962 - val_loss: 0.3232 - val_categorical_accuracy: 0.9057\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3418 - categorical_accuracy: 0.8963 - val_loss: 0.3214 - val_categorical_accuracy: 0.9067\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3401 - categorical_accuracy: 0.8971 - val_loss: 0.3198 - val_categorical_accuracy: 0.9077\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3383 - categorical_accuracy: 0.8979 - val_loss: 0.3184 - val_categorical_accuracy: 0.9086\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3366 - categorical_accuracy: 0.8982 - val_loss: 0.3169 - val_categorical_accuracy: 0.9080\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3349 - categorical_accuracy: 0.8987 - val_loss: 0.3153 - val_categorical_accuracy: 0.9088\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3333 - categorical_accuracy: 0.8997 - val_loss: 0.3139 - val_categorical_accuracy: 0.9097\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3317 - categorical_accuracy: 0.8994 - val_loss: 0.3125 - val_categorical_accuracy: 0.9101\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3301 - categorical_accuracy: 0.9004 - val_loss: 0.3111 - val_categorical_accuracy: 0.9106\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3285 - categorical_accuracy: 0.9010 - val_loss: 0.3097 - val_categorical_accuracy: 0.9103\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3269 - categorical_accuracy: 0.9015 - val_loss: 0.3083 - val_categorical_accuracy: 0.9107\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3255 - categorical_accuracy: 0.9010 - val_loss: 0.3070 - val_categorical_accuracy: 0.9110\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3240 - categorical_accuracy: 0.9022 - val_loss: 0.3057 - val_categorical_accuracy: 0.9121\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3225 - categorical_accuracy: 0.9025 - val_loss: 0.3046 - val_categorical_accuracy: 0.9121\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3210 - categorical_accuracy: 0.9032 - val_loss: 0.3031 - val_categorical_accuracy: 0.9122\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3197 - categorical_accuracy: 0.9035 - val_loss: 0.3019 - val_categorical_accuracy: 0.9123\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3182 - categorical_accuracy: 0.9035 - val_loss: 0.3008 - val_categorical_accuracy: 0.9127\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3170 - categorical_accuracy: 0.9042 - val_loss: 0.2996 - val_categorical_accuracy: 0.9127\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3155 - categorical_accuracy: 0.9044 - val_loss: 0.2983 - val_categorical_accuracy: 0.9135\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3142 - categorical_accuracy: 0.9049 - val_loss: 0.2972 - val_categorical_accuracy: 0.9138\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3129 - categorical_accuracy: 0.9053 - val_loss: 0.2961 - val_categorical_accuracy: 0.9144\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3116 - categorical_accuracy: 0.9056 - val_loss: 0.2951 - val_categorical_accuracy: 0.9140\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3104 - categorical_accuracy: 0.9056 - val_loss: 0.2939 - val_categorical_accuracy: 0.9143\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3092 - categorical_accuracy: 0.9065 - val_loss: 0.2928 - val_categorical_accuracy: 0.9152\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3079 - categorical_accuracy: 0.9066 - val_loss: 0.2918 - val_categorical_accuracy: 0.9148\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3067 - categorical_accuracy: 0.9070 - val_loss: 0.2905 - val_categorical_accuracy: 0.9153\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3055 - categorical_accuracy: 0.9072 - val_loss: 0.2896 - val_categorical_accuracy: 0.9163\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3043 - categorical_accuracy: 0.9077 - val_loss: 0.2885 - val_categorical_accuracy: 0.9161\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3032 - categorical_accuracy: 0.9078 - val_loss: 0.2874 - val_categorical_accuracy: 0.9163\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3020 - categorical_accuracy: 0.9081 - val_loss: 0.2866 - val_categorical_accuracy: 0.9167\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3009 - categorical_accuracy: 0.9085 - val_loss: 0.2853 - val_categorical_accuracy: 0.9168\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2997 - categorical_accuracy: 0.9089 - val_loss: 0.2844 - val_categorical_accuracy: 0.9168\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2986 - categorical_accuracy: 0.9090 - val_loss: 0.2834 - val_categorical_accuracy: 0.9175\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2976 - categorical_accuracy: 0.9093 - val_loss: 0.2824 - val_categorical_accuracy: 0.9174\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2965 - categorical_accuracy: 0.9095 - val_loss: 0.2814 - val_categorical_accuracy: 0.9177\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2954 - categorical_accuracy: 0.9097 - val_loss: 0.2807 - val_categorical_accuracy: 0.9170\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2943 - categorical_accuracy: 0.9097 - val_loss: 0.2795 - val_categorical_accuracy: 0.9177\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2932 - categorical_accuracy: 0.9107 - val_loss: 0.2786 - val_categorical_accuracy: 0.9177\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2922 - categorical_accuracy: 0.9108 - val_loss: 0.2777 - val_categorical_accuracy: 0.9176\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2912 - categorical_accuracy: 0.9111 - val_loss: 0.2768 - val_categorical_accuracy: 0.9188\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2901 - categorical_accuracy: 0.9112 - val_loss: 0.2762 - val_categorical_accuracy: 0.9184\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2891 - categorical_accuracy: 0.9120 - val_loss: 0.2750 - val_categorical_accuracy: 0.9191\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2881 - categorical_accuracy: 0.9118 - val_loss: 0.2742 - val_categorical_accuracy: 0.9182\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2871 - categorical_accuracy: 0.9126 - val_loss: 0.2736 - val_categorical_accuracy: 0.9195\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2861 - categorical_accuracy: 0.9129 - val_loss: 0.2724 - val_categorical_accuracy: 0.9208\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2851 - categorical_accuracy: 0.9130 - val_loss: 0.2716 - val_categorical_accuracy: 0.9200\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2842 - categorical_accuracy: 0.9132 - val_loss: 0.2707 - val_categorical_accuracy: 0.9204\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2832 - categorical_accuracy: 0.9141 - val_loss: 0.2700 - val_categorical_accuracy: 0.9207\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2823 - categorical_accuracy: 0.9140 - val_loss: 0.2689 - val_categorical_accuracy: 0.9206\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2813 - categorical_accuracy: 0.9142 - val_loss: 0.2684 - val_categorical_accuracy: 0.9205\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2804 - categorical_accuracy: 0.9145 - val_loss: 0.2675 - val_categorical_accuracy: 0.9214\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2795 - categorical_accuracy: 0.9148 - val_loss: 0.2666 - val_categorical_accuracy: 0.9206\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2785 - categorical_accuracy: 0.9148 - val_loss: 0.2658 - val_categorical_accuracy: 0.9212\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2777 - categorical_accuracy: 0.9156 - val_loss: 0.2651 - val_categorical_accuracy: 0.9221\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2768 - categorical_accuracy: 0.9156 - val_loss: 0.2642 - val_categorical_accuracy: 0.9217\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2759 - categorical_accuracy: 0.9164 - val_loss: 0.2634 - val_categorical_accuracy: 0.9224\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2749 - categorical_accuracy: 0.9158 - val_loss: 0.2627 - val_categorical_accuracy: 0.9231\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2741 - categorical_accuracy: 0.9167 - val_loss: 0.2620 - val_categorical_accuracy: 0.9239\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2733 - categorical_accuracy: 0.9168 - val_loss: 0.2611 - val_categorical_accuracy: 0.9229\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2724 - categorical_accuracy: 0.9168 - val_loss: 0.2605 - val_categorical_accuracy: 0.9236\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2716 - categorical_accuracy: 0.9173 - val_loss: 0.2597 - val_categorical_accuracy: 0.9242\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2707 - categorical_accuracy: 0.9176 - val_loss: 0.2592 - val_categorical_accuracy: 0.9237\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2699 - categorical_accuracy: 0.9182 - val_loss: 0.2582 - val_categorical_accuracy: 0.9232\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2691 - categorical_accuracy: 0.9183 - val_loss: 0.2575 - val_categorical_accuracy: 0.9244\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2682 - categorical_accuracy: 0.9188 - val_loss: 0.2571 - val_categorical_accuracy: 0.9247\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2675 - categorical_accuracy: 0.9188 - val_loss: 0.2561 - val_categorical_accuracy: 0.9244\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2666 - categorical_accuracy: 0.9192 - val_loss: 0.2554 - val_categorical_accuracy: 0.9250\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2658 - categorical_accuracy: 0.9194 - val_loss: 0.2547 - val_categorical_accuracy: 0.9252\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2650 - categorical_accuracy: 0.9202 - val_loss: 0.2543 - val_categorical_accuracy: 0.9249\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2642 - categorical_accuracy: 0.9199 - val_loss: 0.2534 - val_categorical_accuracy: 0.9254\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2634 - categorical_accuracy: 0.9201 - val_loss: 0.2526 - val_categorical_accuracy: 0.9248\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2626 - categorical_accuracy: 0.9203 - val_loss: 0.2520 - val_categorical_accuracy: 0.9256\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2619 - categorical_accuracy: 0.9203 - val_loss: 0.2516 - val_categorical_accuracy: 0.9253\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2611 - categorical_accuracy: 0.9204 - val_loss: 0.2506 - val_categorical_accuracy: 0.9265\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2603 - categorical_accuracy: 0.9210 - val_loss: 0.2501 - val_categorical_accuracy: 0.9254\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2596 - categorical_accuracy: 0.9212 - val_loss: 0.2495 - val_categorical_accuracy: 0.9264\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2588 - categorical_accuracy: 0.9218 - val_loss: 0.2489 - val_categorical_accuracy: 0.9263\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2581 - categorical_accuracy: 0.9215 - val_loss: 0.2481 - val_categorical_accuracy: 0.9269\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2573 - categorical_accuracy: 0.9221 - val_loss: 0.2475 - val_categorical_accuracy: 0.9272\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2566 - categorical_accuracy: 0.9221 - val_loss: 0.2468 - val_categorical_accuracy: 0.9276\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2559 - categorical_accuracy: 0.9223 - val_loss: 0.2465 - val_categorical_accuracy: 0.9273\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2551 - categorical_accuracy: 0.9224 - val_loss: 0.2457 - val_categorical_accuracy: 0.9280\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2544 - categorical_accuracy: 0.9224 - val_loss: 0.2452 - val_categorical_accuracy: 0.9279\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2537 - categorical_accuracy: 0.9226 - val_loss: 0.2448 - val_categorical_accuracy: 0.9277\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2530 - categorical_accuracy: 0.9227 - val_loss: 0.2441 - val_categorical_accuracy: 0.9277\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2523 - categorical_accuracy: 0.9232 - val_loss: 0.2434 - val_categorical_accuracy: 0.9284\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2516 - categorical_accuracy: 0.9234 - val_loss: 0.2428 - val_categorical_accuracy: 0.9283\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2509 - categorical_accuracy: 0.9234 - val_loss: 0.2419 - val_categorical_accuracy: 0.9297\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2502 - categorical_accuracy: 0.9234 - val_loss: 0.2415 - val_categorical_accuracy: 0.9293\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2496 - categorical_accuracy: 0.9234 - val_loss: 0.2408 - val_categorical_accuracy: 0.9293\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2488 - categorical_accuracy: 0.9242 - val_loss: 0.2404 - val_categorical_accuracy: 0.9298\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2482 - categorical_accuracy: 0.9240 - val_loss: 0.2397 - val_categorical_accuracy: 0.9297\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2475 - categorical_accuracy: 0.9240 - val_loss: 0.2391 - val_categorical_accuracy: 0.9296\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2469 - categorical_accuracy: 0.9248 - val_loss: 0.2388 - val_categorical_accuracy: 0.9300\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2462 - categorical_accuracy: 0.9245 - val_loss: 0.2381 - val_categorical_accuracy: 0.9300\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2456 - categorical_accuracy: 0.9248 - val_loss: 0.2375 - val_categorical_accuracy: 0.9304\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2449 - categorical_accuracy: 0.9248 - val_loss: 0.2370 - val_categorical_accuracy: 0.9304\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2442 - categorical_accuracy: 0.9253 - val_loss: 0.2370 - val_categorical_accuracy: 0.9297\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2436 - categorical_accuracy: 0.9252 - val_loss: 0.2359 - val_categorical_accuracy: 0.9312\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2430 - categorical_accuracy: 0.9256 - val_loss: 0.2355 - val_categorical_accuracy: 0.9310\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2424 - categorical_accuracy: 0.9259 - val_loss: 0.2350 - val_categorical_accuracy: 0.9306\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2418 - categorical_accuracy: 0.9258 - val_loss: 0.2343 - val_categorical_accuracy: 0.9316\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2412 - categorical_accuracy: 0.9263 - val_loss: 0.2338 - val_categorical_accuracy: 0.9314\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2405 - categorical_accuracy: 0.9263 - val_loss: 0.2333 - val_categorical_accuracy: 0.9312\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2400 - categorical_accuracy: 0.9259 - val_loss: 0.2327 - val_categorical_accuracy: 0.9319\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2393 - categorical_accuracy: 0.9269 - val_loss: 0.2323 - val_categorical_accuracy: 0.9320\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2387 - categorical_accuracy: 0.9267 - val_loss: 0.2318 - val_categorical_accuracy: 0.9322\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2381 - categorical_accuracy: 0.9269 - val_loss: 0.2313 - val_categorical_accuracy: 0.9319\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2375 - categorical_accuracy: 0.9273 - val_loss: 0.2307 - val_categorical_accuracy: 0.9322\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2370 - categorical_accuracy: 0.9272 - val_loss: 0.2302 - val_categorical_accuracy: 0.9328\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2363 - categorical_accuracy: 0.9275 - val_loss: 0.2300 - val_categorical_accuracy: 0.9325\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2359 - categorical_accuracy: 0.9274 - val_loss: 0.2292 - val_categorical_accuracy: 0.9328\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2352 - categorical_accuracy: 0.9278 - val_loss: 0.2288 - val_categorical_accuracy: 0.9334\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2346 - categorical_accuracy: 0.9278 - val_loss: 0.2282 - val_categorical_accuracy: 0.9329\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2341 - categorical_accuracy: 0.9283 - val_loss: 0.2278 - val_categorical_accuracy: 0.9332\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2335 - categorical_accuracy: 0.9280 - val_loss: 0.2273 - val_categorical_accuracy: 0.9336\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2329 - categorical_accuracy: 0.9284 - val_loss: 0.2268 - val_categorical_accuracy: 0.9337\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2324 - categorical_accuracy: 0.9289 - val_loss: 0.2264 - val_categorical_accuracy: 0.9339\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2318 - categorical_accuracy: 0.9288 - val_loss: 0.2259 - val_categorical_accuracy: 0.9343\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2314 - categorical_accuracy: 0.9292 - val_loss: 0.2254 - val_categorical_accuracy: 0.9343\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2308 - categorical_accuracy: 0.9289 - val_loss: 0.2250 - val_categorical_accuracy: 0.9343\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2302 - categorical_accuracy: 0.9295 - val_loss: 0.2246 - val_categorical_accuracy: 0.9340\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2297 - categorical_accuracy: 0.9294 - val_loss: 0.2243 - val_categorical_accuracy: 0.9343\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2292 - categorical_accuracy: 0.9296 - val_loss: 0.2237 - val_categorical_accuracy: 0.9344\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2286 - categorical_accuracy: 0.9298 - val_loss: 0.2232 - val_categorical_accuracy: 0.9348\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.2281 - categorical_accuracy: 0.9300 - val_loss: 0.2228 - val_categorical_accuracy: 0.9348\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2276 - categorical_accuracy: 0.9304 - val_loss: 0.2222 - val_categorical_accuracy: 0.9352\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2271 - categorical_accuracy: 0.9307 - val_loss: 0.2220 - val_categorical_accuracy: 0.9349\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2266 - categorical_accuracy: 0.9303 - val_loss: 0.2214 - val_categorical_accuracy: 0.9354\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2260 - categorical_accuracy: 0.9305 - val_loss: 0.2211 - val_categorical_accuracy: 0.9358\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2255 - categorical_accuracy: 0.9311 - val_loss: 0.2205 - val_categorical_accuracy: 0.9353\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2250 - categorical_accuracy: 0.9311 - val_loss: 0.2201 - val_categorical_accuracy: 0.9361\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2244 - categorical_accuracy: 0.9311 - val_loss: 0.2201 - val_categorical_accuracy: 0.9362\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2240 - categorical_accuracy: 0.9314 - val_loss: 0.2193 - val_categorical_accuracy: 0.9358\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2235 - categorical_accuracy: 0.9316 - val_loss: 0.2189 - val_categorical_accuracy: 0.9362\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2230 - categorical_accuracy: 0.9318 - val_loss: 0.2186 - val_categorical_accuracy: 0.9359\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2225 - categorical_accuracy: 0.9320 - val_loss: 0.2183 - val_categorical_accuracy: 0.9358\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2221 - categorical_accuracy: 0.9319 - val_loss: 0.2178 - val_categorical_accuracy: 0.9363\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2216 - categorical_accuracy: 0.9320 - val_loss: 0.2173 - val_categorical_accuracy: 0.9363\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2211 - categorical_accuracy: 0.9322 - val_loss: 0.2169 - val_categorical_accuracy: 0.9371\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2206 - categorical_accuracy: 0.9324 - val_loss: 0.2168 - val_categorical_accuracy: 0.9371\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2201 - categorical_accuracy: 0.9325 - val_loss: 0.2161 - val_categorical_accuracy: 0.9367\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2197 - categorical_accuracy: 0.9324 - val_loss: 0.2157 - val_categorical_accuracy: 0.9367\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2192 - categorical_accuracy: 0.9330 - val_loss: 0.2154 - val_categorical_accuracy: 0.9377\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(60000,49) # 7x7\n",
    "X_test=X_test.reshape(10000,49)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(49,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,batch_size=128, epochs=200, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Test score: 0.21038885685503483\n",
      "Test accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance is not bad, albeit not as good as our previous attemptes having a deep network find features themselves. To better understand this: when training the network with the full 28x28 pixels, we are letting the network sift through 784 bytes of data to make a decision, which digit an input depicts. In particular, we have no idea what happens inside the network and what it actually ends up looking for. This is different when doing some of the pre-processing ourselves. Specifically, we decided that the majority of the information should be contained in whether a subset of 7x7 \"super-pixels\" are populated or not. We are then training on the reduced feature set that is represented by only 49 bytes - 16 times less.\n",
    "\n",
    "Albeit we might be able to hand-engineer better features than those chosen here, even some that are able to ultimately beat a brute-force neural network approach in terms of accuracy, machine learning has developed tools that have made hand-engineering features obsolete, rather take advantage of neural network architectures that in themselves perform preprocessing that are conducive to image and speech recognition. These are known as <i>convolutional neural networks</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal training parameters\n",
    "\n",
    "Albeit poking around with the different options of the variying machine learning toolkits is a lot easier than hand-coding features, and decisions can partly be informed by a fundamental understanding of the underlying methods (such as provided by this course), what works and what does not still heavily depends on the data actually at hand. For example, the \"batch size\" is a parameter for which only rough guidelines can be given. Often, playing with certain parameters or even systematically sweeping them can provide some intuition. For example, we can easily test the impact of different batch sizes, by training a model with a couple of different ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_sizes=[8,16,32,64,128,256,512]\n",
    "#batch_sizes=[128,256,512]\n",
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES,input_shape=(784,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['categorical_accuracy'])\n",
    "\n",
    "score=np.zeros((len(batch_sizes),2))\n",
    "times=np.zeros((len(batch_sizes),2))\n",
    "\n",
    "for I, batch_size in enumerate(batch_sizes):\n",
    "    t=time.time()\n",
    "    history = model.fit(X_train, Y_train,batch_size=batch_size, verbose=0, epochs=20, validation_split=VALIDATION_SPLIT)\n",
    "    score[I] = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    times[I] = time.time()-t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_sizes,score[:,1])\n",
    "plt.plot(batch_sizes,score[:,1],'*')\n",
    "plt.ylabel('Categorical accuracy')\n",
    "plt.xlabel('Batch size')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(batch_sizes,times)\n",
    "plt.plot(batch_sizes,times,'*')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.xlabel('Batch size')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above experiment, that the batch size actually has an optimum. If too low, the gradient jumps back and forth for every new training instance, if too high, the gradient combines too many experiences into one. We also observe, however, that training becomes much, much slower with smaller batch sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- Coding features by hand as much as possible has been the standard approach to design a machine learning algorithm for many decades. The idea has been that hand-coding leverages as much human expert knowledge as possible, while reducing the data sufficiently to make training a neural network actually tractable. \n",
    "- The ability to train also larger networks efficiently, has allowed to create \"deep\" neural networks that can get very good performance, sometimes even exceeding those of solutions relying on hand-coded features, without much tuning whatsoever.\n",
    "- We have introduced a new feature, using a part of the test set for validation. This can help the training algorithm in many ways, for example detecting overfitting, stopping once a certain performance on valiation is met, and others.\n",
    "- Albeit the validation set can help to determine the optimal number of epochs, that is the number of times a dataset is presented to the network, the \"batch size\" remains a free parameter. If too low, weights are updated for every training instance, which is very susceptive to noise. If too high, the gradient is averaged over too many instances at once, ignoring possibly important information such as particularly salient examples.  \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
