{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective functions and optimization\n",
    "\n",
    "The key idea to train neural networks is to change the network's parameters so that a certain objective function, also called loss function, is minimized. This is usually done by evaluating the gradient of this objective function with respect to the network's parameters. So far, we have considered the so-called <i>Mean-squared Error</i> (MSE)\n",
    "\n",
    "$$ E=\\frac{1}{2N}\\sum_{i=1}^{N}(\\hat{y_i}(w)-y_i)^2 $$\n",
    "\n",
    "which is the average error over a set of $N$ pairs of predictions $\\hat{y}$ that are dependent on the network parameters $w$ and known values $y$. This function is particularly convenient, as the square makes it convex, allowing to find its minimum by following its gradient (\"gradient descent\"), which we have seen for the backpropagation algorithm in the last chapter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A drawback of MSE is that only poorly deals with outliers. Consider the following simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1103b4685059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;31m# Introduce outlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from \n",
    "y=np.random.random(10)\n",
    "y[10]=10 # Introduce outlier\n",
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“MSE: This is the mean squared error between the predictions and the true values. Mathematically, if  is a vector of n predictions, and Y is the vector of n observed values, then they satisfy the following equation:\n",
    "\n",
    "These objective functions average all the mistakes made for each prediction, and if the prediction is far from the true value, then this distance is made more evident by the squaring operation.”\n",
    "\n",
    "Excerpt From: Antonio Gulli. “Deep Learning with Keras.” Apple Books. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Binary cross-entropy: This is the binary logarithmic loss. Suppose that our model predicts p while the target is t, then the binary cross-entropy is defined as follows:\n",
    "\n",
    "This objective function is suitable for binary labels prediction.”\n",
    "\n",
    "Excerpt From: Antonio Gulli. “Deep Learning with Keras.” Apple Books. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Categorical cross-entropy: This is the multiclass logarithmic loss. If the target is ti,j and the prediction is pi,j, then the categorical cross-entropy is this:\n",
    "\n",
    "This objective function is suitable for multiclass labels predictions. It is also the default choice in association with softmax activation.”\n",
    "\n",
    "Excerpt From: Antonio Gulli. “Deep Learning with Keras.” Apple Books. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
